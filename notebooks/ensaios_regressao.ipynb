{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmos: Linear Regression, Decision Tree Regressor, Random Forest Regressor, Polinomial Regression, Linear Regression Lasso, Linear Regression Ridge, Linear Regression Elastic Net,Polinomial Regression Lasso, Polinomial Regression Ridge e Polinomial Regression Elastic Net\n",
    "\n",
    "## Métricas de performance: R2, MSE, RMSE, MAE e MAPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics as mt\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import SelectKBest, f_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobre os dados de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados de treino\n",
    "x_train = pd.read_csv(\"../../dataset/Regressao/Treino/x_training.csv\")\n",
    "y_train = pd.read_csv(\"../../dataset/Regressao/Treino/y_training.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "song_duration_ms    147\n",
      "acousticness          0\n",
      "danceability         24\n",
      "energy                2\n",
      "instrumentalness    579\n",
      "key                   0\n",
      "liveness            289\n",
      "loudness            195\n",
      "audio_mode            0\n",
      "speechiness         218\n",
      "tempo                19\n",
      "time_signature      621\n",
      "audio_valence         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Identificando outliers\n",
    "\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Calcular Z-Score\n",
    "z_scores = x_train.apply(zscore)\n",
    "\n",
    "# Identificar outliers\n",
    "outliers = (z_scores.abs() > 3)\n",
    "print(outliers.sum())  # Contagem de outliers por coluna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1000 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Identificando outliers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_train.hist(figsize=(12, 10), bins=30)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensão original: (10547, 14)\n",
      "Dimensão após remoção de outliers: (10019, 14)\n"
     ]
    }
   ],
   "source": [
    "#Removendo outliers\n",
    "\n",
    "# Juntar DataFrames\n",
    "data_train = pd.concat([x_train, y_train], axis=1)\n",
    "\n",
    "# Configurar o Isolation Forest\n",
    "iso = IsolationForest(contamination=0.05, random_state=42)\n",
    "iso.fit(data_train)\n",
    "\n",
    "# Prever outliers (-1 indica outliers, 1 valores normais)\n",
    "outlier_predictions = iso.predict(data_train)\n",
    "\n",
    "# Remover os outliers\n",
    "data_train_cleaned = data_train[outlier_predictions == 1]\n",
    "\n",
    "# Separar x_train e y_train novamente\n",
    "x_train = data_train_cleaned.iloc[:, :-1]  \n",
    "y_train = data_train_cleaned.iloc[:, -1]  \n",
    "\n",
    "# Verificar dimensões antes e depois\n",
    "print(f\"Dimensão original: {data_train.shape}\")\n",
    "print(f\"Dimensão após remoção de outliers: {data_train_cleaned.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seleção de features\n",
    "\n",
    "# Selecionar as 5 melhores features\n",
    "selector = SelectKBest(score_func=f_regression, k=5)\n",
    "x_train = selector.fit_transform(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treino do modelo sem outliers\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "lr_model.fit(x_train,y_train)\n",
    "\n",
    "y_pred = lr_model.predict(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 4.61%\n",
      "MSE: 451.46\n",
      "RMSE: 21.247588098417193\n",
      "MAE: 16.89445044941176\n",
      "MAPE: 787.9976871426866%\n"
     ]
    }
   ],
   "source": [
    "linear_regression_train_R2 = r2_squared_out_10 = np.round(100 * mt.r2_score(y_train, y_pred), 2)\n",
    "linear_regression_train_MSE = mse_out_10 = np.round(mt.mean_squared_error(y_train, y_pred), 2)\n",
    "linear_regression_train_RMSE = rmse_out_10 = np.sqrt(mse_out_10)\n",
    "linear_regression_train_MAE = mt.mean_absolute_error(y_train, y_pred)\n",
    "linear_regression_train_MAPE = mt.mean_absolute_percentage_error(y_train, y_pred) * 100\n",
    "\n",
    "print(f\"R²: {linear_regression_train_R2}%\")\n",
    "print(f\"MSE: {linear_regression_train_MSE}\")\n",
    "print(f\"RMSE: {linear_regression_train_RMSE}\")\n",
    "print(f\"MAE: {linear_regression_train_MAE}\")\n",
    "print(f\"MAPE: {linear_regression_train_MAPE}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobre os dados de validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados de treino\n",
    "x_train = pd.read_csv(\"../../dataset/Regressao/Treino/x_training.csv\")\n",
    "y_train = pd.read_csv(\"../../dataset/Regressao/Treino/y_training.csv\")\n",
    "\n",
    "# Dados de validação\n",
    "x_val = pd.read_csv(\"../../dataset/Regressao/Validacao/X_validation.csv\")\n",
    "y_val = pd.read_csv(\"../../dataset/Regressao/Validacao/y_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensão original: (10547, 14)\n",
      "Dimensão após remoção de outliers: (10019, 14)\n"
     ]
    }
   ],
   "source": [
    "#Removendo outliers dos dados de treino\n",
    "\n",
    "# Juntar DatraFrames\n",
    "data_train = pd.concat([x_train, y_train], axis=1)\n",
    "\n",
    "# Configurar o Isolation Forest\n",
    "iso = IsolationForest(contamination=0.05, random_state=42)\n",
    "iso.fit(data_train)\n",
    "\n",
    "# Prever outliers (-1 indica outliers, 1 valores normais)\n",
    "outlier_predictions = iso.predict(data_train)\n",
    "\n",
    "# Remover os outliers\n",
    "data_train_cleaned = data_train[outlier_predictions == 1]\n",
    "\n",
    "# Separar x_train e y_train novamente\n",
    "x_train = data_train_cleaned.iloc[:, :-1]  \n",
    "y_train = data_train_cleaned.iloc[:, -1]  \n",
    "\n",
    "# Verificar dimensões antes e depois\n",
    "print(f\"Dimensão original: {data_train.shape}\")\n",
    "print(f\"Dimensão após remoção de outliers: {data_train_cleaned.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensão original: (4521, 14)\n",
      "Dimensão após remoção de outliers: (4313, 14)\n"
     ]
    }
   ],
   "source": [
    "# Removendo outliers dos dados de validação usando o modelo treinado com dados de treino\n",
    "\n",
    "data_val = pd.concat([x_val, y_val], axis=1)\n",
    "\n",
    "# Prever outliers (-1 indica outliers, 1 valores normais)\n",
    "outlier_predictions = iso.predict(data_val)\n",
    "\n",
    "# Remover os outliers\n",
    "data_val_cleaned = data_val[outlier_predictions == 1]\n",
    "\n",
    "# Separar x_val e y_val novamente\n",
    "x_val = data_val_cleaned.iloc[:, :-1]  \n",
    "y_val = data_val_cleaned.iloc[:, -1]   \n",
    "\n",
    "# Verificar dimensões antes e depois\n",
    "print(f\"Dimensão original: {data_val.shape}\")\n",
    "print(f\"Dimensão após remoção de outliers: {data_val_cleaned.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar as 5 melhores features\n",
    "selector = SelectKBest(score_func=f_regression, k=5)\n",
    "\n",
    "# Ajustar o selector nos dados originais e transformá-los\n",
    "selector.fit(x_train, y_train)\n",
    "x_train = selector.transform(x_train)\n",
    "\n",
    "# Transformar os dados de validação com as mesmas features\n",
    "x_val = selector.transform(x_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treinamento do modelo\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "lr_model.fit(x_train,y_train)\n",
    "\n",
    "y_pred = lr_model.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 4.19%\n",
      "MSE: 454.86\n",
      "RMSE: 21.327447104611466\n",
      "MAE: 16.94128461968674\n",
      "MAPE: 8.238156045198368\n"
     ]
    }
   ],
   "source": [
    "#Métricas de performance para dados de validação\n",
    "\n",
    "linear_regression_val_R2 = r2_squared_out_10 = np.round(100 * mt.r2_score(y_val, y_pred), 2)\n",
    "linear_regression_val_MSE = mse_out_10 = np.round(mt.mean_squared_error(y_val, y_pred), 2)\n",
    "linear_regression_val_RMSE = rmse_out_10 = np.sqrt(mse_out_10)\n",
    "linear_regression_val_MAE = mt.mean_absolute_error(y_val, y_pred)\n",
    "linear_regression_val_MAPE = mt.mean_absolute_percentage_error(y_val, y_pred)\n",
    "\n",
    "print(f\"R²: {linear_regression_val_R2}%\")\n",
    "print(f\"MSE: {linear_regression_val_MSE}\")\n",
    "print(f\"RMSE: {linear_regression_val_RMSE}\")\n",
    "print(f\"MAE: {linear_regression_val_MAE}\")\n",
    "print(f\"MAPE: {linear_regression_val_MAPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobre os dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados de treino\n",
    "x_train = pd.read_csv(\"../../dataset/Regressao/Treino/x_training.csv\")\n",
    "y_train = pd.read_csv(\"../../dataset/Regressao/Treino/y_training.csv\")\n",
    "\n",
    "# Dados de validação\n",
    "x_val = pd.read_csv(\"../../dataset/Regressao/Validacao/X_validation.csv\")\n",
    "y_val = pd.read_csv(\"../../dataset/Regressao/Validacao/y_val.csv\")\n",
    "\n",
    "# Dados de Teste\n",
    "\n",
    "x_test = pd.read_csv(\"../../dataset/Regressao/Teste/X_test.csv\")\n",
    "y_test = pd.read_csv(\"../../dataset/Regressao/Teste/y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensão original: (10547, 14)\n",
      "Dimensão após remoção de outliers: (10019, 14)\n"
     ]
    }
   ],
   "source": [
    "#Removendo outliers dos dados de treino\n",
    "\n",
    "# Juntar DataFrames\n",
    "data_train = pd.concat([x_train, y_train], axis=1)\n",
    "\n",
    "# Configurar o Isolation Forest\n",
    "iso = IsolationForest(contamination=0.05, random_state=42)\n",
    "iso.fit(data_train)\n",
    "\n",
    "# Prever outliers (-1 indica outliers, 1 valores normais)\n",
    "outlier_predictions = iso.predict(data_train)\n",
    "\n",
    "# Remover os outliers\n",
    "data_train_cleaned = data_train[outlier_predictions == 1]\n",
    "\n",
    "# Separar x_train e y_train novamente\n",
    "x_train = data_train_cleaned.iloc[:, :-1]  \n",
    "y_train = data_train_cleaned.iloc[:, -1]   \n",
    "\n",
    "# Verificar dimensões antes e depois\n",
    "print(f\"Dimensão original: {data_train.shape}\")\n",
    "print(f\"Dimensão após remoção de outliers: {data_train_cleaned.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensão original: (4521, 14)\n",
      "Dimensão após remoção de outliers: (4313, 14)\n"
     ]
    }
   ],
   "source": [
    "# Removendo outliers dos dados de validação usando o modelo treinado com dados de treino\n",
    "\n",
    "data_val = pd.concat([x_val, y_val], axis=1)\n",
    "\n",
    "# Prever outliers (-1 indica outliers, 1 valores normais)\n",
    "outlier_predictions = iso.predict(data_val)\n",
    "\n",
    "# Remover os outliers\n",
    "data_val_cleaned = data_val[outlier_predictions == 1]\n",
    "\n",
    "# Separar x_val e y_val novamente\n",
    "x_val = data_val_cleaned.iloc[:, :-1]  # Todas as colunas exceto a última\n",
    "y_val = data_val_cleaned.iloc[:, -1]   # Apenas a última coluna (y_train)\n",
    "\n",
    "# Verificar dimensões antes e depois\n",
    "print(f\"Dimensão original: {data_val.shape}\")\n",
    "print(f\"Dimensão após remoção de outliers: {data_val_cleaned.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensão original: (3767, 14)\n",
      "Dimensão após remoção de outliers: (3587, 14)\n"
     ]
    }
   ],
   "source": [
    "# Removendo outliers dos dados de teste usando o modelo treinado com dados de treino\n",
    "\n",
    "data_test = pd.concat([x_test, y_test], axis=1)\n",
    "\n",
    "# Prever outliers (-1 indica outliers, 1 valores normais)\n",
    "outlier_predictions = iso.predict(data_test)\n",
    "\n",
    "# Remover os outliers\n",
    "data_test_cleaned = data_test[outlier_predictions == 1]\n",
    "\n",
    "# Separar x_test e y_test\n",
    "x_test = data_test_cleaned.iloc[:, :-1] \n",
    "y_test = data_test_cleaned.iloc[:, -1]   \n",
    "\n",
    "# Verificar dimensões antes e depois\n",
    "print(f\"Dimensão original: {data_test.shape}\")\n",
    "print(f\"Dimensão após remoção de outliers: {data_test_cleaned.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar as 5 melhores features\n",
    "selector = SelectKBest(score_func=f_regression, k=5)\n",
    "\n",
    "# Ajustar o selector nos dados originais e transformá-los\n",
    "selector.fit(x_train, y_train)\n",
    "x_train = selector.transform(x_train)\n",
    "\n",
    "# Transformar os dados de validação com as mesmas features\n",
    "x_val = selector.transform(x_val)\n",
    "\n",
    "# Transformar os dados de teste com as mesmas features\n",
    "x_test = selector.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treinamento do modelo com dados de treino e validação juntos\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "lr_model.fit(np.concatenate( (x_train, x_val) ), np.concatenate((y_train, y_val)))\n",
    "\n",
    "y_pred = lr_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 4.27%\n",
      "MSE: 460.47\n",
      "RMSE: 21.458564723671525\n",
      "MAE: 17.1101521266827\n",
      "MAPE: 8.010272953827318\n"
     ]
    }
   ],
   "source": [
    "#Métricas de performance para dados de teste\n",
    "\n",
    "linear_regression_test_R2 = r2_squared_out_10 = np.round(100 * mt.r2_score(y_test, y_pred), 2)\n",
    "linear_regression_test_MSE = mse_out_10 = np.round(mt.mean_squared_error(y_test, y_pred), 2)\n",
    "linear_regression_test_RMSE = rmse_out_10 = np.sqrt(mse_out_10)\n",
    "linear_regression_test_MAE = mt.mean_absolute_error(y_test, y_pred)\n",
    "linear_regression_test_MAPE = mt.mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "print(f\"R²: {linear_regression_test_R2}%\")\n",
    "print(f\"MSE: {linear_regression_test_MSE}\")\n",
    "print(f\"RMSE: {linear_regression_test_RMSE}\")\n",
    "print(f\"MAE: {linear_regression_test_MAE}\")\n",
    "print(f\"MAPE: {linear_regression_test_MAPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn.metrics as mt\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobre os dados de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando dados de treinamento\n",
    "x_train = pd.read_csv(\"../../dataset/Regressao/Treino/X_training.csv\")\n",
    "y_train = pd.read_csv(\"../../dataset/Regressao/Treino/y_training.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Melhores parâmetros: {'max_depth': 5}\n"
     ]
    }
   ],
   "source": [
    "#Escolhendo melhores parâmetros\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 10, None],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=DecisionTreeRegressor(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Melhor modelo\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"Melhores parâmetros:\", grid_search.best_params_)\n",
    "\n",
    "best_max_depth = grid_search.best_params_['max_depth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treinamento do modelo com os melhores parâmetros\n",
    "\n",
    "model = DecisionTreeRegressor(max_depth=best_max_depth)\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 11.35%\n",
      "MSE: 423.75\n",
      "RMSE: 20.5851888502389\n",
      "MAE: 16.368766312461414\n",
      "MAPE: 7.869536027810438\n"
     ]
    }
   ],
   "source": [
    "#Métricas de performance para dados de treino\n",
    "\n",
    "decision_tree_regression_train_R2 = r2_squared_out_10 = np.round(100 * mt.r2_score(y_train, y_pred), 2)\n",
    "decision_tree_regression_train_MSE = mse_out_10 = np.round(mt.mean_squared_error(y_train, y_pred), 2)\n",
    "decision_tree_regression_train_RMSE = rmse_out_10 = np.sqrt(mse_out_10)\n",
    "decision_tree_regression_train_MAE = mt.mean_absolute_error(y_train, y_pred)\n",
    "decision_tree_regression_train_MAPE = mt.mean_absolute_percentage_error(y_train, y_pred)\n",
    "\n",
    "print(f\"R²: {decision_tree_regression_train_R2}%\")\n",
    "print(f\"MSE: {decision_tree_regression_train_MSE}\")\n",
    "print(f\"RMSE: {decision_tree_regression_train_RMSE}\")\n",
    "print(f\"MAE: {decision_tree_regression_train_MAE}\")\n",
    "print(f\"MAPE: {decision_tree_regression_train_MAPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobre os dados de validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando dados de treinamento\n",
    "x_train = pd.read_csv(\"../../dataset/Regressao/Treino/X_training.csv\")\n",
    "y_train = pd.read_csv(\"../../dataset/Regressao/Treino/y_training.csv\")\n",
    "\n",
    "#Importando dados de validação\n",
    "x_val = pd.read_csv(\"../../dataset/Regressao/Validacao/X_validation.csv\")\n",
    "y_val = pd.read_csv(\"../../dataset/Regressao/Validacao/y_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Melhores parâmetros: {'max_depth': 5}\n"
     ]
    }
   ],
   "source": [
    "#Escolhendo melhores parâmetros\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 10, None],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=DecisionTreeRegressor(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Melhor modelo\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"Melhores parâmetros:\", grid_search.best_params_)\n",
    "\n",
    "best_max_depth = grid_search.best_params_['max_depth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treinamento do modelo com os melhores parâmetros\n",
    "\n",
    "model = DecisionTreeRegressor(max_depth=best_max_depth)\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 6.36%\n",
      "MSE: 447.16\n",
      "RMSE: 21.14615804348393\n",
      "MAE: 16.843451865846717\n",
      "MAPE: 8.395778483246199\n"
     ]
    }
   ],
   "source": [
    "#Métricas de performance para dados de validação\n",
    "\n",
    "decision_tree_regression_val_R2 = r2_squared_out_10 = np.round(100 * mt.r2_score(y_val, y_pred), 2)\n",
    "decision_tree_regression_val_MSE = mse_out_10 = np.round(mt.mean_squared_error(y_val, y_pred), 2)\n",
    "decision_tree_regression_val_RMSE = rmse_out_10 = np.sqrt(mse_out_10)\n",
    "decision_tree_regression_val_MAE = mt.mean_absolute_error(y_val, y_pred)\n",
    "decision_tree_regression_val_MAPE = mt.mean_absolute_percentage_error(y_val, y_pred)\n",
    "\n",
    "print(f\"R²: {decision_tree_regression_val_R2}%\")\n",
    "print(f\"MSE: {decision_tree_regression_val_MSE}\")\n",
    "print(f\"RMSE: {decision_tree_regression_val_RMSE}\")\n",
    "print(f\"MAE: {decision_tree_regression_val_MAE}\")\n",
    "print(f\"MAPE: {decision_tree_regression_val_MAPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobre os dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando dados de treinamento\n",
    "x_train = pd.read_csv(\"../../dataset/Regressao/Treino/X_training.csv\")\n",
    "y_train = pd.read_csv(\"../../dataset/Regressao/Treino/y_training.csv\")\n",
    "\n",
    "#Importando dados de validação\n",
    "x_val = pd.read_csv(\"../../dataset/Regressao/Validacao/X_validation.csv\")\n",
    "y_val = pd.read_csv(\"../../dataset/Regressao/Validacao/y_val.csv\")\n",
    "\n",
    "#Importando dados de teste\n",
    "x_test = pd.read_csv(\"../../dataset/Regressao/Teste/X_test.csv\")\n",
    "y_test = pd.read_csv(\"../../dataset/Regressao/Teste/y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Melhores parâmetros: {'max_depth': 5}\n"
     ]
    }
   ],
   "source": [
    "#Escolhendo melhores parâmetros\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 10, None],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=DecisionTreeRegressor(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Melhor modelo\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"Melhores parâmetros:\", grid_search.best_params_)\n",
    "\n",
    "best_max_depth = grid_search.best_params_['max_depth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:457: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Treinamento do modelo com os melhores parâmetros   \n",
    "model = DecisionTreeRegressor(max_depth=best_max_depth)\n",
    "model.fit(np.concatenate( (x_train, x_val) ), np.concatenate((y_train, y_val)))\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 9.05%\n",
      "MSE: 442.85\n",
      "RMSE: 21.0440015206234\n",
      "MAE: 16.82978094998882\n",
      "MAPE: 7.883226145162678\n"
     ]
    }
   ],
   "source": [
    "#Métricas de performance para dados de teste\n",
    "\n",
    "decision_tree_regression_test_R2 = r2_squared_out_10 = np.round(100 * mt.r2_score(y_test, y_pred), 2)\n",
    "decision_tree_regression_test_MSE = mse_out_10 = np.round(mt.mean_squared_error(y_test, y_pred), 2)\n",
    "decision_tree_regression_test_RMSE = rmse_out_10 = np.sqrt(mse_out_10)\n",
    "decision_tree_regression_test_MAE = mt.mean_absolute_error(y_test, y_pred)\n",
    "decision_tree_regression_test_MAPE = mt.mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "print(f\"R²: {decision_tree_regression_test_R2}%\")\n",
    "print(f\"MSE: {decision_tree_regression_test_MSE}\")\n",
    "print(f\"RMSE: {decision_tree_regression_test_RMSE}\")\n",
    "print(f\"MAE: {decision_tree_regression_test_MAE}\")\n",
    "print(f\"MAPE: {decision_tree_regression_test_MAPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as mt\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobre os dados de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando dados de treinamento\n",
    "x_train = pd.read_csv(\"../../dataset/Regressao/Treino/X_training.csv\")\n",
    "y_train = pd.read_csv(\"../../dataset/Regressao/Treino/y_training.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reduzindo o conjunto de dados de forma aleatória\n",
    "\n",
    "# Amostra aleatória sem reposição\n",
    "x_sample, y_sample = resample(\n",
    "    x_train, y_train,\n",
    "    n_samples=1000,       # Quantidade de amostras desejadas\n",
    "    random_state=42       # Garantir reprodutibilidade\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros encontrados: {'n_estimators': 700, 'max_depth': 40}\n",
      "Melhor desempenho (neg_mean_squared_error): -425.63700643677555\n"
     ]
    }
   ],
   "source": [
    "# Parâmetros para busca aleatória\n",
    "param_dist = {\n",
    "    'n_estimators': [int(x) for x in np.linspace(start=100, stop=1000, num=10)],\n",
    "    'max_depth': [int(x) for x in np.linspace(10, 110, num=11)] + [None]\n",
    "}\n",
    "\n",
    "# Instancia o modelo RandomForestRegressor\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# RandomizedSearchCV para busca aleatória\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf,                     \n",
    "    param_distributions=param_dist,   \n",
    "    n_iter=100,                       \n",
    "    cv=5,                             \n",
    "    scoring='neg_mean_squared_error', \n",
    "    verbose=2,                        \n",
    "    random_state=42,                  \n",
    "    n_jobs=-1                         \n",
    ")\n",
    "\n",
    "# Realiza a busca com os dados de treino\n",
    "random_search.fit(x_sample, y_sample)\n",
    "\n",
    "# Exibe os melhores parâmetros encontrados\n",
    "print(\"Melhores parâmetros encontrados:\", random_search.best_params_)\n",
    "print(\"Melhor desempenho (neg_mean_squared_error):\", random_search.best_score_)\n",
    "\n",
    "# Selecionar cada parâmetro individualmente\n",
    "best_n_estimators = random_search.best_params_['n_estimators']\n",
    "best_max_depth = random_search.best_params_['max_depth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Treinamento do algoritmo\n",
    "rf = RandomForestRegressor(max_depth=best_max_depth,n_estimators=best_n_estimators,random_state=42)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "#Previsão\n",
    "y_pred = rf.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 90.63%\n",
      "MSE: 44.81\n",
      "RMSE: 6.694027188471825\n",
      "MAE: 4.798755091740677\n",
      "MAPE: 2.6280371046999225\n"
     ]
    }
   ],
   "source": [
    "#Métricas de performance para dados de treino\n",
    "\n",
    "random_forest_regressor_train_R2 = r2_squared_out_10 = np.round(100 * mt.r2_score(y_train, y_pred), 2)\n",
    "random_forest_regressor_train_MSE = mse_out_10 = np.round(mt.mean_squared_error(y_train, y_pred), 2)\n",
    "random_forest_regressor_train_RMSE = rmse_out_10 = np.sqrt(mse_out_10)\n",
    "random_forest_regressor_train_MAE = mt.mean_absolute_error(y_train, y_pred)\n",
    "random_forest_regressor_train_MAPE = mt.mean_absolute_percentage_error(y_train, y_pred)\n",
    "\n",
    "print(f\"R²: {random_forest_regressor_train_R2}%\")\n",
    "print(f\"MSE: {random_forest_regressor_train_MSE}\")\n",
    "print(f\"RMSE: {random_forest_regressor_train_RMSE}\")\n",
    "print(f\"MAE: {random_forest_regressor_train_MAE}\")\n",
    "print(f\"MAPE: {random_forest_regressor_train_MAPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobre os dados de validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando dados de treinamento\n",
    "x_train = pd.read_csv(\"../../dataset/Regressao/Treino/X_training.csv\")\n",
    "y_train = pd.read_csv(\"../../dataset/Regressao/Treino/y_training.csv\")\n",
    "\n",
    "#Importando dados de validação\n",
    "x_val = pd.read_csv(\"../../dataset/Regressao/Validacao/X_validation.csv\")\n",
    "y_val = pd.read_csv(\"../../dataset/Regressao/Validacao/y_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros encontrados: {'n_estimators': 300, 'max_depth': 70}\n",
      "Melhor desempenho (neg_mean_squared_error): -425.92373099288886\n"
     ]
    }
   ],
   "source": [
    "# Parâmetros para busca aleatória\n",
    "param_dist = {\n",
    "    'n_estimators': [int(x) for x in np.linspace(start=100, stop=1000, num=10)],\n",
    "    'max_depth': [int(x) for x in np.linspace(10, 110, num=11)] + [None]\n",
    "}\n",
    "\n",
    "# Instancia o modelo RandomForestRegressor\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# RandomizedSearchCV para busca aleatória\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf,                     \n",
    "    param_distributions=param_dist,   \n",
    "    n_iter=100,                       \n",
    "    cv=5,                             \n",
    "    scoring='neg_mean_squared_error', \n",
    "    verbose=2,                        \n",
    "    random_state=42,                  \n",
    "    n_jobs=-1                         \n",
    ")\n",
    "\n",
    "# Realiza a busca com os dados de treino\n",
    "random_search.fit(x_sample, y_sample)\n",
    "\n",
    "# Exibe os melhores parâmetros encontrados\n",
    "print(\"Melhores parâmetros encontrados:\", random_search.best_params_)\n",
    "print(\"Melhor desempenho (neg_mean_squared_error):\", random_search.best_score_)\n",
    "\n",
    "# Selecionar cada parâmetro individualmente\n",
    "best_n_estimators = random_search.best_params_['n_estimators']\n",
    "best_max_depth = random_search.best_params_['max_depth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Treinamento do algoritmo\n",
    "rf = RandomForestRegressor(max_depth=best_max_depth, n_estimators=best_n_estimators, random_state=42)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "#Previsão\n",
    "y_pred = rf.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 34.0%\n",
      "MSE: 315.14\n",
      "RMSE: 17.752182964356805\n",
      "MAE: 12.935710613307187\n",
      "MAPE: 7.036928486212441\n"
     ]
    }
   ],
   "source": [
    "#Métricas de performance para dados de validação\n",
    "\n",
    "random_forest_regressor_val_R2 = r2_squared_out_10 = np.round(100 * mt.r2_score(y_val, y_pred), 2)\n",
    "random_forest_regressor_val_MSE = mse_out_10 = np.round(mt.mean_squared_error(y_val, y_pred), 2)\n",
    "random_forest_regressor_val_RMSE = rmse_out_10 = np.sqrt(mse_out_10)\n",
    "random_forest_regressor_val_MAE = mt.mean_absolute_error(y_val, y_pred)\n",
    "random_forest_regressor_val_MAPE = mt.mean_absolute_percentage_error(y_val, y_pred)\n",
    "\n",
    "print(f\"R²: {random_forest_regressor_val_R2}%\")\n",
    "print(f\"MSE: {random_forest_regressor_val_MSE}\")\n",
    "print(f\"RMSE: {random_forest_regressor_val_RMSE}\")\n",
    "print(f\"MAE: {random_forest_regressor_val_MAE}\")\n",
    "print(f\"MAPE: {random_forest_regressor_val_MAPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobre os dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando dados de treinamento\n",
    "x_train = pd.read_csv(\"../../dataset/Regressao/Treino/X_training.csv\")\n",
    "y_train = pd.read_csv(\"../../dataset/Regressao/Treino/y_training.csv\")\n",
    "\n",
    "#Importando dados de validação\n",
    "x_val = pd.read_csv(\"../../dataset/Regressao/Validacao/X_validation.csv\")\n",
    "y_val = pd.read_csv(\"../../dataset/Regressao/Validacao/y_val.csv\")\n",
    "\n",
    "#Importando dados de teste\n",
    "x_test = pd.read_csv(\"../../dataset/Regressao/Teste/X_test.csv\")\n",
    "y_test = pd.read_csv(\"../../dataset/Regressao/Teste/y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros encontrados: {'n_estimators': 400, 'max_depth': 80}\n",
      "Melhor desempenho (neg_mean_squared_error): -426.0661666240625\n"
     ]
    }
   ],
   "source": [
    "# Parâmetros para busca aleatória\n",
    "param_dist = {\n",
    "    'n_estimators': [int(x) for x in np.linspace(start=100, stop=1000, num=10)],\n",
    "    'max_depth': [int(x) for x in np.linspace(10, 110, num=11)] + [None]\n",
    "}\n",
    "\n",
    "# Instancia o modelo RandomForestRegressor\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# RandomizedSearchCV para busca aleatória\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf,                     \n",
    "    param_distributions=param_dist,   \n",
    "    n_iter=100,                       \n",
    "    cv=5,                             \n",
    "    scoring='neg_mean_squared_error', \n",
    "    verbose=2,                        \n",
    "    random_state=42,                  \n",
    "    n_jobs=-1                         \n",
    ")\n",
    "\n",
    "# Realiza a busca com os dados de treino\n",
    "random_search.fit(x_sample, y_sample)\n",
    "\n",
    "# Exibe os melhores parâmetros encontrados\n",
    "print(\"Melhores parâmetros encontrados:\", random_search.best_params_)\n",
    "print(\"Melhor desempenho (neg_mean_squared_error):\", random_search.best_score_)\n",
    "\n",
    "# Selecionar cada parâmetro individualmente\n",
    "best_n_estimators = random_search.best_params_['n_estimators']\n",
    "best_max_depth = random_search.best_params_['max_depth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Treinamento do algoritmo\n",
    "rf = RandomForestRegressor(max_depth=best_max_depth, n_estimators=best_n_estimators, random_state=42)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "#Previsão\n",
    "y_pred = rf.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 33.86%\n",
      "MSE: 315.82\n",
      "RMSE: 17.771325217889633\n",
      "MAE: 12.950201466701158\n",
      "MAPE: 7.054799143427394\n"
     ]
    }
   ],
   "source": [
    "#Métricas de performance para dados de validação\n",
    "\n",
    "random_forest_regressor_test_R2 = r2_squared_out_10 = np.round(100 * mt.r2_score(y_val, y_pred), 2)\n",
    "random_forest_regressor_test_MSE = mse_out_10 = np.round(mt.mean_squared_error(y_val, y_pred), 2)\n",
    "random_forest_regressor_test_RMSE = rmse_out_10 = np.sqrt(mse_out_10)\n",
    "random_forest_regressor_test_MAE = mt.mean_absolute_error(y_val, y_pred)\n",
    "random_forest_regressor_test_MAPE = mt.mean_absolute_percentage_error(y_val, y_pred)\n",
    "\n",
    "print(f\"R²: {random_forest_regressor_test_R2}%\")\n",
    "print(f\"MSE: {random_forest_regressor_test_MSE}\")\n",
    "print(f\"RMSE: {random_forest_regressor_test_RMSE}\")\n",
    "print(f\"MAE: {random_forest_regressor_test_MAE}\")\n",
    "print(f\"MAPE: {random_forest_regressor_test_MAPE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:457: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Treinamento do algoritmo\n",
    "rf = RandomForestRegressor(max_depth=best_max_depth, n_estimators=best_n_estimators, random_state=42)\n",
    "rf.fit(np.concatenate( (x_train, x_val) ), np.concatenate((y_train, y_val)))\n",
    "\n",
    "#Previsão\n",
    "y_pred = rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 40.62%\n",
      "MSE: 289.11\n",
      "RMSE: 17.003234986319516\n",
      "MAE: 12.21033327728429\n",
      "MAPE: 6.282725794215609\n"
     ]
    }
   ],
   "source": [
    "#Métricas de performance para dados de teste\n",
    "\n",
    "random_forest_regressor_test_R2 = r2_squared_out_10 = np.round(100 * mt.r2_score(y_test, y_pred), 2)\n",
    "random_forest_regressor_test_MSE = mse_out_10 = np.round(mt.mean_squared_error(y_test, y_pred), 2)\n",
    "random_forest_regressor_test_RMSE = rmse_out_10 = np.sqrt(mse_out_10)\n",
    "random_forest_regressor_test_MAE = mt.mean_absolute_error(y_test, y_pred)\n",
    "random_forest_regressor_test_MAPE = mt.mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "print(f\"R²: {random_forest_regressor_test_R2}%\")\n",
    "print(f\"MSE: {random_forest_regressor_test_MSE}\")\n",
    "print(f\"RMSE: {random_forest_regressor_test_RMSE}\")\n",
    "print(f\"MAE: {random_forest_regressor_test_MAE}\")\n",
    "print(f\"MAPE: {random_forest_regressor_test_MAPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polinomial Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics as mt\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobre os dados de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando dados de treinamento\n",
    "x_train = pd.read_csv(\"../../dataset/Regressao/Treino/X_training.csv\")\n",
    "y_train = pd.read_csv(\"../../dataset/Regressao/Treino/y_training.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor grau polinomial: 5\n"
     ]
    }
   ],
   "source": [
    "degrees = [1, 2, 3, 4, 5]  # Graus a serem testados\n",
    "errors = []  # Para armazenar erros \n",
    "\n",
    "for degree in degrees:\n",
    "    # Transformar para características polinomiais\n",
    "    poly_features = PolynomialFeatures(degree=degree)\n",
    "    x_train_poly = poly_features.fit_transform(x_train)\n",
    "    \n",
    "    # Treinar modelo\n",
    "    model = LinearRegression()\n",
    "    model.fit(x_train_poly, y_train)\n",
    "    \n",
    "    # Prever nos dados de treino\n",
    "    y_train_pred = model.predict(x_train_poly)\n",
    "    train_error = mean_squared_error(y_train, y_train_pred)\n",
    "    errors.append(train_error)\n",
    "\n",
    "# Escolher o melhor grau\n",
    "best_degree = degrees[np.argmin(errors)]\n",
    "print(f\"Melhor grau polinomial: {best_degree}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformar os dados em características polinomiais\n",
    "poly_features = PolynomialFeatures(degree=best_degree)\n",
    "\n",
    "x_train_poly = poly_features.fit_transform(x_train)\n",
    "\n",
    "# Treinar o modelo\n",
    "model = LinearRegression()\n",
    "model.fit(x_train_poly, y_train)\n",
    "\n",
    "# Previsão do algoritmo\n",
    "y_pred = model.predict(x_train_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 72.53%\n",
      "MSE: 131.31\n",
      "RMSE: 11.459057552870568\n",
      "MAE: 7.266166434089909\n",
      "MAPE: 2.215335300014142\n"
     ]
    }
   ],
   "source": [
    "#Métricas de performance para dados de treino\n",
    "\n",
    "polinomial_regression_train_R2 = r2_squared_out_10 = np.round(100 * mt.r2_score(y_train, y_pred), 2)\n",
    "polinomial_regression_train_MSE = mse_out_10 = np.round(mt.mean_squared_error(y_train, y_pred), 2)\n",
    "polinomial_regression_train_RMSE = rmse_out_10 = np.sqrt(mse_out_10)\n",
    "polinomial_regression_train_MAE = mt.mean_absolute_error(y_train, y_pred)\n",
    "polinomial_regression_train_MAPE = mt.mean_absolute_percentage_error(y_train, y_pred)\n",
    "\n",
    "print(f\"R²: {polinomial_regression_train_R2}%\")\n",
    "print(f\"MSE: {polinomial_regression_train_MSE}\")\n",
    "print(f\"RMSE: {polinomial_regression_train_RMSE}\")\n",
    "print(f\"MAE: {polinomial_regression_train_MAE}\")\n",
    "print(f\"MAPE: {polinomial_regression_train_MAPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobre os dados de validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando dados de treinamento\n",
    "x_train = pd.read_csv(\"../../dataset/Regressao/Treino/X_training.csv\")\n",
    "y_train = pd.read_csv(\"../../dataset/Regressao/Treino/y_training.csv\")\n",
    "\n",
    "#Importando dados de validação\n",
    "x_val = pd.read_csv(\"../../dataset/Regressao/Validacao/X_validation.csv\")\n",
    "y_val = pd.read_csv(\"../../dataset/Regressao/Validacao/y_val.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor grau polinomial: 2\n"
     ]
    }
   ],
   "source": [
    "degrees = [1, 2, 3, 4, 5]  # Graus a serem testados\n",
    "validation_errors = []  # Para armazenar erros de validação\n",
    "\n",
    "for degree in degrees:\n",
    "    # Transformar para características polinomiais\n",
    "    poly_features = PolynomialFeatures(degree=degree)\n",
    "    X_train_poly = poly_features.fit_transform(x_train)\n",
    "    X_val_poly = poly_features.transform(x_val)\n",
    "    \n",
    "    # Treinar modelo\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_poly, y_train)\n",
    "    \n",
    "    # Prever nos dados de validação\n",
    "    y_val_pred = model.predict(X_val_poly)\n",
    "    val_error = mean_squared_error(y_val, y_val_pred)\n",
    "    validation_errors.append(val_error)\n",
    "\n",
    "# Escolher o melhor grau\n",
    "best_degree = degrees[np.argmin(validation_errors)]\n",
    "print(f\"Melhor grau polinomial: {best_degree}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformar os dados em características polinomiais\n",
    "poly_features = PolynomialFeatures(degree=best_degree)\n",
    "\n",
    "x_train_poly = poly_features.fit_transform(x_train)\n",
    "x_val_poly = poly_features.transform(x_val)\n",
    "\n",
    "# Treinar o modelo\n",
    "model = LinearRegression()\n",
    "model.fit(x_train_poly, y_train)\n",
    "\n",
    "# Previsão do algoritmo\n",
    "y_pred = model.predict(x_val_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 6.65%\n",
      "MSE: 445.77\n",
      "RMSE: 21.11326597189549\n",
      "MAE: 16.749939090484027\n",
      "MAPE: 8.54793103460539\n"
     ]
    }
   ],
   "source": [
    "#Métricas de performance para dados de validação\n",
    "\n",
    "polinomial_regression_val_R2 = r2_squared_out_10 = np.round(100 * mt.r2_score(y_val, y_pred), 2)\n",
    "polinomial_regression_val_MSE = mse_out_10 = np.round(mt.mean_squared_error(y_val, y_pred), 2)\n",
    "polinomial_regression_val_RMSE = rmse_out_10 = np.sqrt(mse_out_10)\n",
    "polinomial_regression_val_MAE = mt.mean_absolute_error(y_val, y_pred)\n",
    "polinomial_regression_val_MAPE = mt.mean_absolute_percentage_error(y_val, y_pred)\n",
    "\n",
    "print(f\"R²: {polinomial_regression_val_R2}%\")\n",
    "print(f\"MSE: {polinomial_regression_val_MSE}\")\n",
    "print(f\"RMSE: {polinomial_regression_val_RMSE}\")\n",
    "print(f\"MAE: {polinomial_regression_val_MAE}\")\n",
    "print(f\"MAPE: {polinomial_regression_val_MAPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobre os dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando dados de treinamento\n",
    "x_train = pd.read_csv(\"../../dataset/Regressao/Treino/X_training.csv\")\n",
    "y_train = pd.read_csv(\"../../dataset/Regressao/Treino/y_training.csv\")\n",
    "\n",
    "#Importando dados de validação\n",
    "x_val = pd.read_csv(\"../../dataset/Regressao/Validacao/X_validation.csv\")\n",
    "y_val = pd.read_csv(\"../../dataset/Regressao/Validacao/y_val.csv\")\n",
    "\n",
    "#Importando dados de teste\n",
    "x_test = pd.read_csv(\"../../dataset/Regressao/Teste/X_test.csv\")\n",
    "y_test = pd.read_csv(\"../../dataset/Regressao/Teste/y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor grau polinomial: 2\n"
     ]
    }
   ],
   "source": [
    "degrees = [1, 2, 3, 4, 5]  # Graus a serem testados\n",
    "validation_errors = []  # Para armazenar erros de validação\n",
    "\n",
    "for degree in degrees:\n",
    "    # Transformar para características polinomiais\n",
    "    poly_features = PolynomialFeatures(degree=degree)\n",
    "    X_train_poly = poly_features.fit_transform(x_train)\n",
    "    X_val_poly = poly_features.transform(x_val)\n",
    "    \n",
    "    # Treinar modelo\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_poly, y_train)\n",
    "    \n",
    "    # Prever nos dados de validação\n",
    "    y_val_pred = model.predict(X_val_poly)\n",
    "    val_error = mean_squared_error(y_val, y_val_pred)\n",
    "    validation_errors.append(val_error)\n",
    "\n",
    "# Escolher o melhor grau\n",
    "best_degree = degrees[np.argmin(validation_errors)]\n",
    "print(f\"Melhor grau polinomial: {best_degree}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformar os dados em características polinomiais\n",
    "poly_features = PolynomialFeatures(degree=best_degree)\n",
    "\n",
    "x_train_poly = poly_features.fit_transform(x_train)\n",
    "x_val_poly = poly_features.transform(x_val)\n",
    "x_test_poly = poly_features.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar o modelo\n",
    "model = LinearRegression()\n",
    "model.fit(x_train_poly, y_train)\n",
    "\n",
    "# Previsão do algoritmo\n",
    "y_pred = model.predict(x_val_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 6.65%\n",
      "MSE: 445.77\n",
      "RMSE: 21.11326597189549\n",
      "MAE: 16.749939090484027\n",
      "MAPE: 8.54793103460539\n"
     ]
    }
   ],
   "source": [
    "#Métricas de performance para dados de validação\n",
    "\n",
    "R2 = r2_squared_out_10 = np.round(100 * mt.r2_score(y_val, y_pred), 2)\n",
    "MSE = mse_out_10 = np.round(mt.mean_squared_error(y_val, y_pred), 2)\n",
    "RMSE = rmse_out_10 = np.sqrt(mse_out_10)\n",
    "MAE = mt.mean_absolute_error(y_val, y_pred)\n",
    "MAPE = mt.mean_absolute_percentage_error(y_val, y_pred)\n",
    "\n",
    "print(f\"R²: {R2}%\")\n",
    "print(f\"MSE: {MSE}\")\n",
    "print(f\"RMSE: {RMSE}\")\n",
    "print(f\"MAE: {MAE}\")\n",
    "print(f\"MAPE: {MAPE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar o modelo\n",
    "model = LinearRegression()\n",
    "model.fit(np.concatenate( (x_train_poly, x_val_poly) ), np.concatenate((y_train, y_val)))\n",
    "\n",
    "# Previsão do algoritmo\n",
    "y_pred = model.predict(x_test_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 9.09%\n",
      "MSE: 442.64\n",
      "RMSE: 21.039011383617815\n",
      "MAE: 16.736414061349993\n",
      "MAPE: 8.276971685015472\n"
     ]
    }
   ],
   "source": [
    "#Métricas de performance para dados de teste\n",
    "\n",
    "polinomial_regression_test_R2 = r2_squared_out_10 = np.round(100 * mt.r2_score(y_test, y_pred), 2)\n",
    "polinomial_regression_test_MSE = mse_out_10 = np.round(mt.mean_squared_error(y_test, y_pred), 2)\n",
    "polinomial_regression_test_RMSE = rmse_out_10 = np.sqrt(mse_out_10)\n",
    "polinomial_regression_test_MAE = mt.mean_absolute_error(y_test, y_pred)\n",
    "polinomial_regression_test_MAPE = mt.mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "print(f\"R²: {polinomial_regression_test_R2}%\")\n",
    "print(f\"MSE: {polinomial_regression_test_MSE}\")\n",
    "print(f\"RMSE: {polinomial_regression_test_RMSE}\")\n",
    "print(f\"MAE: {polinomial_regression_test_MAE}\")\n",
    "print(f\"MAPE: {polinomial_regression_test_MAPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn.metrics as mt\n",
    "from sklearn.linear_model import Lasso\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobre os dados de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando dados de treinamento\n",
    "x_train = pd.read_csv(\"../../dataset/Regressao/Treino/X_training.csv\")\n",
    "y_train = pd.read_csv(\"../../dataset/Regressao/Treino/y_training.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.01, Max Iter: 100, Validation MSE: 456.0574152288833\n",
      "Alpha: 0.01, Max Iter: 500, Validation MSE: 456.0574152288833\n",
      "Alpha: 0.01, Max Iter: 1000, Validation MSE: 456.0574152288833\n",
      "Alpha: 0.01, Max Iter: 2000, Validation MSE: 456.0574152288833\n",
      "Alpha: 0.1, Max Iter: 100, Validation MSE: 458.3093966319514\n",
      "Alpha: 0.1, Max Iter: 500, Validation MSE: 458.3093966319514\n",
      "Alpha: 0.1, Max Iter: 1000, Validation MSE: 458.3093966319514\n",
      "Alpha: 0.1, Max Iter: 2000, Validation MSE: 458.3093966319514\n",
      "Alpha: 1, Max Iter: 100, Validation MSE: 474.47483414340275\n",
      "Alpha: 1, Max Iter: 500, Validation MSE: 474.47483414340275\n",
      "Alpha: 1, Max Iter: 1000, Validation MSE: 474.47483414340275\n",
      "Alpha: 1, Max Iter: 2000, Validation MSE: 474.47483414340275\n",
      "Alpha: 10, Max Iter: 100, Validation MSE: 478.012559979818\n",
      "Alpha: 10, Max Iter: 500, Validation MSE: 478.012559979818\n",
      "Alpha: 10, Max Iter: 1000, Validation MSE: 478.012559979818\n",
      "Alpha: 10, Max Iter: 2000, Validation MSE: 478.012559979818\n",
      "Alpha: 20, Max Iter: 100, Validation MSE: 478.012559979818\n",
      "Alpha: 20, Max Iter: 500, Validation MSE: 478.012559979818\n",
      "Alpha: 20, Max Iter: 1000, Validation MSE: 478.012559979818\n",
      "Alpha: 20, Max Iter: 2000, Validation MSE: 478.012559979818\n",
      "Best Alpha: 0.01, Best Max Iter: 100\n"
     ]
    }
   ],
   "source": [
    "#Escolha do melhor parâmetro\n",
    "\n",
    "alphas = [0.01, 0.1, 1, 10,20]\n",
    "max_iters = [100, 500, 1000, 2000]\n",
    "best_alpha = None\n",
    "best_score = float('inf')\n",
    "\n",
    "for alpha in alphas:\n",
    "    for max_iter in max_iters:\n",
    "        # Instanciar e treinar o modelo\n",
    "        lasso = Lasso(alpha=alpha, max_iter=max_iter, random_state=42)\n",
    "        lasso.fit(x_train, y_train)\n",
    "\n",
    "        # Avaliar no conjunto de treino\n",
    "        y_train_pred = lasso.predict(x_train)\n",
    "        score = mt.mean_squared_error(y_train, y_train_pred)\n",
    "\n",
    "        print(f\"Alpha: {alpha}, Max Iter: {max_iter}, Validation MSE: {score}\")\n",
    "\n",
    "        # Atualizar os melhores parâmetros\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_alpha = alpha\n",
    "            best_max_iter = max_iter\n",
    "\n",
    "print(f\"Best Alpha: {best_alpha}, Best Max Iter: {best_max_iter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treinamento do modelo\n",
    "\n",
    "lasso = Lasso(alpha=best_alpha,max_iter=best_max_iter, random_state=42)\n",
    "lasso.fit(x_train, y_train)\n",
    "y_pred = lasso.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 4.593%\n",
      "MSE: 456.06\n",
      "RMSE: 21.35556133656992\n",
      "MAE: 17.00211535840327\n",
      "MAPE: 8.660670204946179\n"
     ]
    }
   ],
   "source": [
    "#Métricas de performance para dados de treino\n",
    "\n",
    "linear_regression_lasso_train_R2 = r2_squared_out_10 = np.round(100 * mt.r2_score(y_train, y_pred), 4)\n",
    "linear_regression_lasso_train_MSE = mse_out_10 = np.round(mt.mean_squared_error(y_train, y_pred), 2)\n",
    "linear_regression_lasso_train_RMSE = rmse_out_10 = np.sqrt(mse_out_10)\n",
    "linear_regression_lasso_train_MAE = mt.mean_absolute_error(y_train, y_pred)\n",
    "linear_regression_lasso_train_MAPE = mt.mean_absolute_percentage_error(y_train, y_pred)\n",
    "\n",
    "print(f\"R²: {linear_regression_lasso_train_R2}%\")\n",
    "print(f\"MSE: {linear_regression_lasso_train_MSE}\")\n",
    "print(f\"RMSE: {linear_regression_lasso_train_RMSE}\")\n",
    "print(f\"MAE: {linear_regression_lasso_train_MAE}\")\n",
    "print(f\"MAPE: {linear_regression_lasso_train_MAPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobre os dados de validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando dados de treinamento\n",
    "x_train = pd.read_csv(\"../../dataset/Regressao/Treino/X_training.csv\")\n",
    "y_train = pd.read_csv(\"../../dataset/Regressao/Treino/y_training.csv\")\n",
    "\n",
    "#Importando dados de validação\n",
    "x_val = pd.read_csv(\"../../dataset/Regressao/Validacao/X_validation.csv\")\n",
    "y_val = pd.read_csv(\"../../dataset/Regressao/Validacao/y_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.01, Max Iter: 100, Validation MSE: 458.4454069886254\n",
      "Alpha: 0.01, Max Iter: 500, Validation MSE: 458.4454069886254\n",
      "Alpha: 0.01, Max Iter: 1000, Validation MSE: 458.4454069886254\n",
      "Alpha: 0.01, Max Iter: 2000, Validation MSE: 458.4454069886254\n",
      "Alpha: 0.1, Max Iter: 100, Validation MSE: 459.75041129600146\n",
      "Alpha: 0.1, Max Iter: 500, Validation MSE: 459.75041129600146\n",
      "Alpha: 0.1, Max Iter: 1000, Validation MSE: 459.75041129600146\n",
      "Alpha: 0.1, Max Iter: 2000, Validation MSE: 459.75041129600146\n",
      "Alpha: 1, Max Iter: 100, Validation MSE: 473.7470809154487\n",
      "Alpha: 1, Max Iter: 500, Validation MSE: 473.7470809154487\n",
      "Alpha: 1, Max Iter: 1000, Validation MSE: 473.7470809154487\n",
      "Alpha: 1, Max Iter: 2000, Validation MSE: 473.7470809154487\n",
      "Alpha: 10, Max Iter: 100, Validation MSE: 477.5119556252973\n",
      "Alpha: 10, Max Iter: 500, Validation MSE: 477.5119556252973\n",
      "Alpha: 10, Max Iter: 1000, Validation MSE: 477.5119556252973\n",
      "Alpha: 10, Max Iter: 2000, Validation MSE: 477.5119556252973\n",
      "Alpha: 20, Max Iter: 100, Validation MSE: 477.5119556252973\n",
      "Alpha: 20, Max Iter: 500, Validation MSE: 477.5119556252973\n",
      "Alpha: 20, Max Iter: 1000, Validation MSE: 477.5119556252973\n",
      "Alpha: 20, Max Iter: 2000, Validation MSE: 477.5119556252973\n",
      "Best Alpha: 0.01, Best Max Iter: 100\n"
     ]
    }
   ],
   "source": [
    "#Escolha do melhor parâmetro\n",
    "\n",
    "alphas = [0.01, 0.1, 1, 10,20]\n",
    "max_iters = [100, 500, 1000, 2000]\n",
    "best_alpha = None\n",
    "best_score = float('inf')\n",
    "\n",
    "for alpha in alphas:\n",
    "    for max_iter in max_iters:\n",
    "        # Instanciar e treinar o modelo\n",
    "        lasso = Lasso(alpha=alpha, max_iter=max_iter, random_state=42)\n",
    "        lasso.fit(x_train, y_train)\n",
    "\n",
    "        # Avaliar no conjunto de validação\n",
    "        y_val_pred = lasso.predict(x_val)\n",
    "        score = mt.mean_squared_error(y_val, y_val_pred)\n",
    "\n",
    "        print(f\"Alpha: {alpha}, Max Iter: {max_iter}, Validation MSE: {score}\")\n",
    "\n",
    "        # Atualizar os melhores parâmetros\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_alpha = alpha\n",
    "            best_max_iter = max_iter\n",
    "\n",
    "print(f\"Best Alpha: {best_alpha}, Best Max Iter: {best_max_iter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treinamento do modelo\n",
    "lasso = Lasso(alpha=best_alpha,max_iter=best_max_iter, random_state=42)\n",
    "lasso.fit(x_train, y_train)\n",
    "\n",
    "#Previsão\n",
    "y_pred = lasso.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 3.99%\n",
      "MSE: 458.45\n",
      "RMSE: 21.411445537375563\n",
      "MAE: 17.03824289549502\n",
      "MAPE: 8.686214930608234\n"
     ]
    }
   ],
   "source": [
    "#Métricas de performance para dados de validação\n",
    "\n",
    "linear_regression_lasso_val_R2 = r2_squared_out_10 = np.round(100 * mt.r2_score(y_val, y_pred), 2)\n",
    "linear_regression_lasso_val_MSE = mse_out_10 = np.round(mt.mean_squared_error(y_val, y_pred), 2)\n",
    "linear_regression_lasso_val_RMSE = rmse_out_10 = np.sqrt(mse_out_10)\n",
    "linear_regression_lasso_val_MAE = mt.mean_absolute_error(y_val, y_pred)\n",
    "linear_regression_lasso_val_MAPE = mt.mean_absolute_percentage_error(y_val, y_pred)\n",
    "\n",
    "print(f\"R²: {linear_regression_lasso_val_R2}%\")\n",
    "print(f\"MSE: {linear_regression_lasso_val_MSE}\")\n",
    "print(f\"RMSE: {linear_regression_lasso_val_RMSE}\")\n",
    "print(f\"MAE: {linear_regression_lasso_val_MAE}\")\n",
    "print(f\"MAPE: {linear_regression_lasso_val_MAPE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobre os dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando dados de treinamento\n",
    "x_train = pd.read_csv(\"../../dataset/Regressao/Treino/X_training.csv\")\n",
    "y_train = pd.read_csv(\"../../dataset/Regressao/Treino/y_training.csv\")\n",
    "\n",
    "#Importando dados de validação\n",
    "x_val = pd.read_csv(\"../../dataset/Regressao/Validacao/X_validation.csv\")\n",
    "y_val = pd.read_csv(\"../../dataset/Regressao/Validacao/y_val.csv\")\n",
    "\n",
    "#Importando dados de teste\n",
    "x_test = pd.read_csv(\"../../dataset/Regressao/Teste/X_test.csv\")\n",
    "y_test = pd.read_csv(\"../../dataset/Regressao/Teste/y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.01, Max Iter: 100, Validation MSE: 458.4454069886254\n",
      "Alpha: 0.01, Max Iter: 500, Validation MSE: 458.4454069886254\n",
      "Alpha: 0.01, Max Iter: 1000, Validation MSE: 458.4454069886254\n",
      "Alpha: 0.01, Max Iter: 2000, Validation MSE: 458.4454069886254\n",
      "Alpha: 0.1, Max Iter: 100, Validation MSE: 459.75041129600146\n",
      "Alpha: 0.1, Max Iter: 500, Validation MSE: 459.75041129600146\n",
      "Alpha: 0.1, Max Iter: 1000, Validation MSE: 459.75041129600146\n",
      "Alpha: 0.1, Max Iter: 2000, Validation MSE: 459.75041129600146\n",
      "Alpha: 1, Max Iter: 100, Validation MSE: 473.7470809154487\n",
      "Alpha: 1, Max Iter: 500, Validation MSE: 473.7470809154487\n",
      "Alpha: 1, Max Iter: 1000, Validation MSE: 473.7470809154487\n",
      "Alpha: 1, Max Iter: 2000, Validation MSE: 473.7470809154487\n",
      "Alpha: 10, Max Iter: 100, Validation MSE: 477.5119556252973\n",
      "Alpha: 10, Max Iter: 500, Validation MSE: 477.5119556252973\n",
      "Alpha: 10, Max Iter: 1000, Validation MSE: 477.5119556252973\n",
      "Alpha: 10, Max Iter: 2000, Validation MSE: 477.5119556252973\n",
      "Alpha: 20, Max Iter: 100, Validation MSE: 477.5119556252973\n",
      "Alpha: 20, Max Iter: 500, Validation MSE: 477.5119556252973\n",
      "Alpha: 20, Max Iter: 1000, Validation MSE: 477.5119556252973\n",
      "Alpha: 20, Max Iter: 2000, Validation MSE: 477.5119556252973\n",
      "Best Alpha: 0.01, Best Max Iter: 100\n"
     ]
    }
   ],
   "source": [
    "#Escolha do melhor parâmetro\n",
    "\n",
    "alphas = [0.01, 0.1, 1, 10,20]\n",
    "max_iters = [100, 500, 1000, 2000]\n",
    "best_alpha = None\n",
    "best_score = float('inf')\n",
    "\n",
    "for alpha in alphas:\n",
    "    for max_iter in max_iters:\n",
    "        # Instanciar e treinar o modelo\n",
    "        lasso = Lasso(alpha=alpha, max_iter=max_iter, random_state=42)\n",
    "        lasso.fit(x_train, y_train)\n",
    "\n",
    "        # Avaliar no conjunto de validação\n",
    "        y_val_pred = lasso.predict(x_val)\n",
    "        score = mt.mean_squared_error(y_val, y_val_pred)\n",
    "\n",
    "        print(f\"Alpha: {alpha}, Max Iter: {max_iter}, Validation MSE: {score}\")\n",
    "\n",
    "        # Atualizar os melhores parâmetros\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_alpha = alpha\n",
    "            best_max_iter = max_iter\n",
    "\n",
    "print(f\"Best Alpha: {best_alpha}, Best Max Iter: {best_max_iter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treinamento do modelo\n",
    "lasso = Lasso(alpha=best_alpha, max_iter=best_max_iter, random_state=42)\n",
    "lasso.fit(x_train, y_train)\n",
    "\n",
    "#Previsão\n",
    "y_pred = lasso.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 3.99%\n",
      "MSE: 458.45\n",
      "RMSE: 21.411445537375563\n",
      "MAE: 17.03824289549502\n",
      "MAPE: 8.686214930608234\n"
     ]
    }
   ],
   "source": [
    "#Métricas de performance para dados de validação\n",
    "\n",
    "R2 = r2_squared_out_10 = np.round(100 * mt.r2_score(y_val, y_pred), 2)\n",
    "MSE = mse_out_10 = np.round(mt.mean_squared_error(y_val, y_pred), 2)\n",
    "RMSE = rmse_out_10 = np.sqrt(mse_out_10)\n",
    "MAE = mt.mean_absolute_error(y_val, y_pred)\n",
    "MAPE = mt.mean_absolute_percentage_error(y_val, y_pred)\n",
    "\n",
    "print(f\"R²: {R2}%\")\n",
    "print(f\"MSE: {MSE}\")\n",
    "print(f\"RMSE: {RMSE}\")\n",
    "print(f\"MAE: {MAE}\")\n",
    "print(f\"MAPE: {MAPE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:457: UserWarning: X has feature names, but Lasso was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Treinamento do modelo\n",
    "lasso = Lasso(alpha=best_alpha,max_iter=best_max_iter, random_state=42)\n",
    "lasso.fit(np.concatenate((x_train, x_val) ), np.concatenate((y_train, y_val)))\n",
    "\n",
    "#Previsão\n",
    "y_pred = lasso.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 5.08%\n",
      "MSE: 462.17\n",
      "RMSE: 21.4981394543807\n",
      "MAE: 17.145311551385827\n",
      "MAPE: 8.549060205507839\n"
     ]
    }
   ],
   "source": [
    "#Métricas de performance para dados de teste\n",
    "\n",
    "linear_regression_lasso_test_R2 = r2_squared_out_10 = np.round(100 * mt.r2_score(y_test, y_pred), 2)\n",
    "linear_regression_lasso_test_MSE = mse_out_10 = np.round(mt.mean_squared_error(y_test, y_pred), 2)\n",
    "linear_regression_lasso_test_RMSE = rmse_out_10 = np.sqrt(mse_out_10)\n",
    "linear_regression_lasso_test_MAE = mt.mean_absolute_error(y_test, y_pred)\n",
    "linear_regression_lasso_test_MAPE = mt.mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "print(f\"R²: {linear_regression_lasso_test_R2}%\")\n",
    "print(f\"MSE: {linear_regression_lasso_test_MSE}\")\n",
    "print(f\"RMSE: {linear_regression_lasso_test_RMSE}\")\n",
    "print(f\"MAE: {linear_regression_lasso_test_MAE}\")\n",
    "print(f\"MAPE: {linear_regression_lasso_test_MAPE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn.metrics as mt\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobre os dados de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando dados de treinamento\n",
    "x_train = pd.read_csv(\"../../dataset/Regressao/Treino/X_training.csv\")\n",
    "y_train = pd.read_csv(\"../../dataset/Regressao/Treino/y_training.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.01, Max Iter: 100, Validation MSE: 455.9961118552722\n",
      "Alpha: 0.01, Max Iter: 500, Validation MSE: 455.9961118552722\n",
      "Alpha: 0.01, Max Iter: 1000, Validation MSE: 455.9961118552722\n",
      "Alpha: 0.01, Max Iter: 2000, Validation MSE: 455.9961118552722\n",
      "Alpha: 0.1, Max Iter: 100, Validation MSE: 455.99611478296237\n",
      "Alpha: 0.1, Max Iter: 500, Validation MSE: 455.99611478296237\n",
      "Alpha: 0.1, Max Iter: 1000, Validation MSE: 455.99611478296237\n",
      "Alpha: 0.1, Max Iter: 2000, Validation MSE: 455.99611478296237\n",
      "Alpha: 1, Max Iter: 100, Validation MSE: 455.99640059223816\n",
      "Alpha: 1, Max Iter: 500, Validation MSE: 455.99640059223816\n",
      "Alpha: 1, Max Iter: 1000, Validation MSE: 455.99640059223816\n",
      "Alpha: 1, Max Iter: 2000, Validation MSE: 455.99640059223816\n",
      "Alpha: 10, Max Iter: 100, Validation MSE: 456.0197627727942\n",
      "Alpha: 10, Max Iter: 500, Validation MSE: 456.0197627727942\n",
      "Alpha: 10, Max Iter: 1000, Validation MSE: 456.0197627727942\n",
      "Alpha: 10, Max Iter: 2000, Validation MSE: 456.0197627727942\n",
      "Alpha: 20, Max Iter: 100, Validation MSE: 456.07622315879615\n",
      "Alpha: 20, Max Iter: 500, Validation MSE: 456.07622315879615\n",
      "Alpha: 20, Max Iter: 1000, Validation MSE: 456.07622315879615\n",
      "Alpha: 20, Max Iter: 2000, Validation MSE: 456.07622315879615\n",
      "Best Alpha: 0.01, Best Max Iter: 100\n"
     ]
    }
   ],
   "source": [
    "#Escolha do melhor parâmetro\n",
    "\n",
    "alphas = [0.01, 0.1, 1, 10,20]\n",
    "max_iters = [100, 500, 1000, 2000]\n",
    "best_alpha = None\n",
    "best_score = float('inf')\n",
    "\n",
    "for alpha in alphas:\n",
    "    for max_iter in max_iters:\n",
    "        # Instanciar e treinar o modelo\n",
    "        ridge = Ridge(alpha=alpha, max_iter=max_iter, random_state=42)\n",
    "        ridge.fit(x_train, y_train)\n",
    "\n",
    "        # Avaliar no conjunto de treino\n",
    "        y_train_pred = ridge.predict(x_train)\n",
    "        score = mt.mean_squared_error(y_train, y_train_pred)\n",
    "\n",
    "        print(f\"Alpha: {alpha}, Max Iter: {max_iter}, Validation MSE: {score}\")\n",
    "\n",
    "        # Atualizar os melhores parâmetros\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_alpha = alpha\n",
    "            best_max_iter = max_iter\n",
    "\n",
    "print(f\"Best Alpha: {best_alpha}, Best Max Iter: {best_max_iter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treinamento do modelo\n",
    "\n",
    "ridge = Ridge(alpha=best_alpha,max_iter=best_max_iter, random_state=42)\n",
    "ridge.fit(x_train, y_train)\n",
    "y_pred = ridge.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 4.6058%\n",
      "MSE: 456.0\n",
      "RMSE: 21.354156504062622\n",
      "MAE: 16.99824967238508\n",
      "MAPE: 8.653188261604535\n"
     ]
    }
   ],
   "source": [
    "#Métricas de performance para dados de treino\n",
    "\n",
    "linear_regression_ridge_train_R2 = r2_squared_out_10 = np.round(100 * mt.r2_score(y_train, y_pred), 4)\n",
    "linear_regression_ridge_train_MSE = mse_out_10 = np.round(mt.mean_squared_error(y_train, y_pred), 2)\n",
    "linear_regression_ridge_train_RMSE = rmse_out_10 = np.sqrt(mse_out_10)\n",
    "linear_regression_ridge_train_MAE = mt.mean_absolute_error(y_train, y_pred)\n",
    "linear_regression_ridge_train_MAPE = mt.mean_absolute_percentage_error(y_train, y_pred)\n",
    "\n",
    "print(f\"R²: {linear_regression_ridge_train_R2}%\")\n",
    "print(f\"MSE: {linear_regression_ridge_train_MSE}\")\n",
    "print(f\"RMSE: {linear_regression_ridge_train_RMSE}\")\n",
    "print(f\"MAE: {linear_regression_ridge_train_MAE}\")\n",
    "print(f\"MAPE: {linear_regression_ridge_train_MAPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobre os dados de validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando dados de treinamento\n",
    "x_train = pd.read_csv(\"../../dataset/Regressao/Treino/X_training.csv\")\n",
    "y_train = pd.read_csv(\"../../dataset/Regressao/Treino/y_training.csv\")\n",
    "\n",
    "#Importando dados de validação\n",
    "x_val = pd.read_csv(\"../../dataset/Regressao/Validacao/X_validation.csv\")\n",
    "y_val = pd.read_csv(\"../../dataset/Regressao/Validacao/y_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.01, Max Iter: 100, Validation MSE: 458.44702495339266\n",
      "Alpha: 0.01, Max Iter: 500, Validation MSE: 458.44702495339266\n",
      "Alpha: 0.01, Max Iter: 1000, Validation MSE: 458.44702495339266\n",
      "Alpha: 0.01, Max Iter: 2000, Validation MSE: 458.44702495339266\n",
      "Alpha: 0.1, Max Iter: 100, Validation MSE: 458.44687408443133\n",
      "Alpha: 0.1, Max Iter: 500, Validation MSE: 458.44687408443133\n",
      "Alpha: 0.1, Max Iter: 1000, Validation MSE: 458.44687408443133\n",
      "Alpha: 0.1, Max Iter: 2000, Validation MSE: 458.44687408443133\n",
      "Alpha: 1, Max Iter: 100, Validation MSE: 458.44547662389704\n",
      "Alpha: 1, Max Iter: 500, Validation MSE: 458.44547662389704\n",
      "Alpha: 1, Max Iter: 1000, Validation MSE: 458.44547662389704\n",
      "Alpha: 1, Max Iter: 2000, Validation MSE: 458.44547662389704\n",
      "Alpha: 10, Max Iter: 100, Validation MSE: 458.4410981845443\n",
      "Alpha: 10, Max Iter: 500, Validation MSE: 458.4410981845443\n",
      "Alpha: 10, Max Iter: 1000, Validation MSE: 458.4410981845443\n",
      "Alpha: 10, Max Iter: 2000, Validation MSE: 458.4410981845443\n",
      "Alpha: 20, Max Iter: 100, Validation MSE: 458.45317205282277\n",
      "Alpha: 20, Max Iter: 500, Validation MSE: 458.45317205282277\n",
      "Alpha: 20, Max Iter: 1000, Validation MSE: 458.45317205282277\n",
      "Alpha: 20, Max Iter: 2000, Validation MSE: 458.45317205282277\n",
      "Best Alpha: 10, Best Max Iter: 100\n"
     ]
    }
   ],
   "source": [
    "#Escolha do melhor parâmetro\n",
    "\n",
    "alphas = [0.01, 0.1, 1, 10,20]\n",
    "max_iters = [100, 500, 1000, 2000]\n",
    "best_alpha = None\n",
    "best_score = float('inf')\n",
    "\n",
    "for alpha in alphas:\n",
    "    for max_iter in max_iters:\n",
    "        # Instanciar e treinar o modelo\n",
    "        ridge = Ridge(alpha=alpha, max_iter=max_iter, random_state=42)\n",
    "        ridge.fit(x_train, y_train)\n",
    "\n",
    "        # Avaliar no conjunto de validação\n",
    "        y_val_pred = ridge.predict(x_val)\n",
    "        score = mt.mean_squared_error(y_val, y_val_pred)\n",
    "\n",
    "        print(f\"Alpha: {alpha}, Max Iter: {max_iter}, Validation MSE: {score}\")\n",
    "\n",
    "        # Atualizar os melhores parâmetros\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_alpha = alpha\n",
    "            best_max_iter = max_iter\n",
    "\n",
    "print(f\"Best Alpha: {best_alpha}, Best Max Iter: {best_max_iter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treinamento do modelo\n",
    "ridge = Ridge(alpha=best_alpha,max_iter=best_max_iter, random_state=42)\n",
    "ridge.fit(x_train, y_train)\n",
    "\n",
    "#Previsão\n",
    "y_pred = ridge.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 3.99%\n",
      "MSE: 458.44\n",
      "RMSE: 21.411212016137714\n",
      "MAE: 17.0376103578882\n",
      "MAPE: 8.681342467801517\n"
     ]
    }
   ],
   "source": [
    "#Métricas de performance para dados de validação\n",
    "\n",
    "linear_regression_ridge_val_R2 = r2_squared_out_10 = np.round(100 * mt.r2_score(y_val, y_pred), 2)\n",
    "linear_regression_ridge_val_MSE = mse_out_10 = np.round(mt.mean_squared_error(y_val, y_pred), 2)\n",
    "linear_regression_ridge_val_RMSE = rmse_out_10 = np.sqrt(mse_out_10)\n",
    "linear_regression_ridge_val_MAE = mt.mean_absolute_error(y_val, y_pred)\n",
    "linear_regression_ridge_val_MAPE = mt.mean_absolute_percentage_error(y_val, y_pred)\n",
    "\n",
    "print(f\"R²: {linear_regression_ridge_val_R2}%\")\n",
    "print(f\"MSE: {linear_regression_ridge_val_MSE}\")\n",
    "print(f\"RMSE: {linear_regression_ridge_val_RMSE}\")\n",
    "print(f\"MAE: {linear_regression_ridge_val_MAE}\")\n",
    "print(f\"MAPE: {linear_regression_ridge_val_MAPE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobre os dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando dados de treinamento\n",
    "x_train = pd.read_csv(\"../../dataset/Regressao/Treino/X_training.csv\")\n",
    "y_train = pd.read_csv(\"../../dataset/Regressao/Treino/y_training.csv\")\n",
    "\n",
    "#Importando dados de validação\n",
    "x_val = pd.read_csv(\"../../dataset/Regressao/Validacao/X_validation.csv\")\n",
    "y_val = pd.read_csv(\"../../dataset/Regressao/Validacao/y_val.csv\")\n",
    "\n",
    "#Importando dados de teste\n",
    "x_test = pd.read_csv(\"../../dataset/Regressao/Teste/X_test.csv\")\n",
    "y_test = pd.read_csv(\"../../dataset/Regressao/Teste/y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.01, Max Iter: 100, Validation MSE: 458.44702495339266"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Alpha: 0.01, Max Iter: 500, Validation MSE: 458.44702495339266\n",
      "Alpha: 0.01, Max Iter: 1000, Validation MSE: 458.44702495339266\n",
      "Alpha: 0.01, Max Iter: 2000, Validation MSE: 458.44702495339266\n",
      "Alpha: 0.1, Max Iter: 100, Validation MSE: 458.44687408443133\n",
      "Alpha: 0.1, Max Iter: 500, Validation MSE: 458.44687408443133\n",
      "Alpha: 0.1, Max Iter: 1000, Validation MSE: 458.44687408443133\n",
      "Alpha: 0.1, Max Iter: 2000, Validation MSE: 458.44687408443133\n",
      "Alpha: 1, Max Iter: 100, Validation MSE: 458.44547662389704\n",
      "Alpha: 1, Max Iter: 500, Validation MSE: 458.44547662389704\n",
      "Alpha: 1, Max Iter: 1000, Validation MSE: 458.44547662389704\n",
      "Alpha: 1, Max Iter: 2000, Validation MSE: 458.44547662389704\n",
      "Alpha: 10, Max Iter: 100, Validation MSE: 458.4410981845443\n",
      "Alpha: 10, Max Iter: 500, Validation MSE: 458.4410981845443\n",
      "Alpha: 10, Max Iter: 1000, Validation MSE: 458.4410981845443\n",
      "Alpha: 10, Max Iter: 2000, Validation MSE: 458.4410981845443\n",
      "Alpha: 20, Max Iter: 100, Validation MSE: 458.45317205282277\n",
      "Alpha: 20, Max Iter: 500, Validation MSE: 458.45317205282277\n",
      "Alpha: 20, Max Iter: 1000, Validation MSE: 458.45317205282277\n",
      "Alpha: 20, Max Iter: 2000, Validation MSE: 458.45317205282277\n",
      "Best Alpha: 10, Best Max Iter: 100\n"
     ]
    }
   ],
   "source": [
    "#Escolha do melhor parâmetro\n",
    "\n",
    "alphas = [0.01, 0.1, 1, 10,20]\n",
    "max_iters = [100, 500, 1000, 2000]\n",
    "best_alpha = None\n",
    "best_score = float('inf')\n",
    "\n",
    "for alpha in alphas:\n",
    "    for max_iter in max_iters:\n",
    "        # Instanciar e treinar o modelo\n",
    "        ridge = Ridge(alpha=alpha, max_iter=max_iter, random_state=42)\n",
    "        ridge.fit(x_train, y_train)\n",
    "\n",
    "        # Avaliar no conjunto de validação\n",
    "        y_val_pred = ridge.predict(x_val)\n",
    "        score = mt.mean_squared_error(y_val, y_val_pred)\n",
    "\n",
    "        print(f\"Alpha: {alpha}, Max Iter: {max_iter}, Validation MSE: {score}\")\n",
    "\n",
    "        # Atualizar os melhores parâmetros\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_alpha = alpha\n",
    "            best_max_iter = max_iter\n",
    "\n",
    "print(f\"Best Alpha: {best_alpha}, Best Max Iter: {best_max_iter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treinamento do modelo\n",
    "ridge = Ridge(alpha=best_alpha, max_iter=best_max_iter, random_state=42)\n",
    "ridge.fit(x_train, y_train)\n",
    "\n",
    "#Previsão\n",
    "y_pred = ridge.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 3.99%\n",
      "MSE: 458.44\n",
      "RMSE: 21.411212016137714\n",
      "MAE: 17.0376103578882\n",
      "MAPE: 8.681342467801517\n"
     ]
    }
   ],
   "source": [
    "#Métricas de performance para dados de validação\n",
    "\n",
    "R2 = r2_squared_out_10 = np.round(100 * mt.r2_score(y_val, y_pred), 2)\n",
    "MSE = mse_out_10 = np.round(mt.mean_squared_error(y_val, y_pred), 2)\n",
    "RMSE = rmse_out_10 = np.sqrt(mse_out_10)\n",
    "MAE = mt.mean_absolute_error(y_val, y_pred)\n",
    "MAPE = mt.mean_absolute_percentage_error(y_val, y_pred)\n",
    "\n",
    "print(f\"R²: {R2}%\")\n",
    "print(f\"MSE: {MSE}\")\n",
    "print(f\"RMSE: {RMSE}\")\n",
    "print(f\"MAE: {MAE}\")\n",
    "print(f\"MAPE: {MAPE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:457: UserWarning: X has feature names, but Ridge was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Treinamento do modelo\n",
    "ridge = Ridge(alpha=best_alpha,max_iter=best_max_iter, random_state=42)\n",
    "ridge.fit(np.concatenate((x_train, x_val) ), np.concatenate((y_train, y_val)))\n",
    "\n",
    "#Previsão\n",
    "y_pred = ridge.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 5.11%\n",
      "MSE: 462.01\n",
      "RMSE: 21.49441787999852\n",
      "MAE: 17.142430127057033\n",
      "MAPE: 8.53781591484164\n"
     ]
    }
   ],
   "source": [
    "#Métricas de performance para dados de teste\n",
    "\n",
    "linear_regression_ridge_test_R2 = r2_squared_out_10 = np.round(100 * mt.r2_score(y_test, y_pred), 2)\n",
    "linear_regression_ridge_test_MSE = mse_out_10 = np.round(mt.mean_squared_error(y_test, y_pred), 2)\n",
    "linear_regression_ridge_test_RMSE = rmse_out_10 = np.sqrt(mse_out_10)\n",
    "linear_regression_ridge_test_MAE = mt.mean_absolute_error(y_test, y_pred)\n",
    "linear_regression_ridge_test_MAPE = mt.mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "print(f\"R²: {linear_regression_ridge_test_R2}%\")\n",
    "print(f\"MSE: {linear_regression_ridge_test_MSE}\")\n",
    "print(f\"RMSE: {linear_regression_ridge_test_RMSE}\")\n",
    "print(f\"MAE: {linear_regression_ridge_test_MAE}\")\n",
    "print(f\"MAPE: {linear_regression_ridge_test_MAPE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Elastic Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn.metrics as mt\n",
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobre os dados de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando dados de treinamento\n",
    "x_train = pd.read_csv(\"../../dataset/Regressao/Treino/X_training.csv\")\n",
    "y_train = pd.read_csv(\"../../dataset/Regressao/Treino/y_training.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Alpha: 0.01, Best Max Iter: 100, Best L1 Ratio: 0.9\n"
     ]
    }
   ],
   "source": [
    "#Escolha do melhor parâmetro\n",
    "\n",
    "alphas = [0.01, 0.1, 1, 10,20]\n",
    "max_iters = [100, 500, 1000, 2000]\n",
    "l1_ratios = [0.1, 0.5, 0.9]\n",
    "best_alpha = None\n",
    "best_score = float('inf')\n",
    "\n",
    "for alpha in alphas:\n",
    "    for max_iter in max_iters:\n",
    "        for l1_ratio in l1_ratios:\n",
    "            # Instanciar e treinar o modelo\n",
    "            elastic_net = ElasticNet(alpha=alpha, max_iter=max_iter,l1_ratio=l1_ratio, random_state=42)\n",
    "            elastic_net.fit(x_train, y_train)\n",
    "\n",
    "            # Avaliar no conjunto de treino\n",
    "            y_train_pred = elastic_net.predict(x_train)\n",
    "            score = mt.mean_squared_error(y_train, y_train_pred)\n",
    "\n",
    "            # Atualizar os melhores parâmetros\n",
    "            if score < best_score:\n",
    "                best_score = score\n",
    "                best_alpha = alpha\n",
    "                best_max_iter = max_iter\n",
    "                best_l1_ratio = l1_ratio\n",
    "\n",
    "print(f\"Best Alpha: {best_alpha}, Best Max Iter: {best_max_iter}, Best L1 Ratio: {best_l1_ratio}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treinamento do modelo\n",
    "\n",
    "elastic_net = ElasticNet(alpha=best_alpha,max_iter=best_max_iter,l1_ratio=best_l1_ratio, random_state=42)\n",
    "elastic_net.fit(x_train, y_train)\n",
    "y_pred = elastic_net.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 4.5808%\n",
      "MSE: 456.12\n",
      "RMSE: 21.356966076669224\n",
      "MAE: 17.003100771694655\n",
      "MAPE: 8.661496845764418\n"
     ]
    }
   ],
   "source": [
    "#Métricas de performance para dados de treino\n",
    "\n",
    "linear_regression_elastic_net_train_R2 = r2_squared_out_10 = np.round(100 * mt.r2_score(y_train, y_pred), 4)\n",
    "linear_regression_elastic_net_train_MSE = mse_out_10 = np.round(mt.mean_squared_error(y_train, y_pred), 2)\n",
    "linear_regression_elastic_net_train_RMSE = rmse_out_10 = np.sqrt(mse_out_10)\n",
    "linear_regression_elastic_net_train_MAE = mt.mean_absolute_error(y_train, y_pred)\n",
    "linear_regression_elastic_net_train_MAPE = mt.mean_absolute_percentage_error(y_train, y_pred)\n",
    "\n",
    "print(f\"R²: {linear_regression_elastic_net_train_R2}%\")\n",
    "print(f\"MSE: {linear_regression_elastic_net_train_MSE}\")\n",
    "print(f\"RMSE: {linear_regression_elastic_net_train_RMSE}\")\n",
    "print(f\"MAE: {linear_regression_elastic_net_train_MAE}\")\n",
    "print(f\"MAPE: {linear_regression_elastic_net_train_MAPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobre os dados de validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando dados de treinamento\n",
    "x_train = pd.read_csv(\"../../dataset/Regressao/Treino/X_training.csv\")\n",
    "y_train = pd.read_csv(\"../../dataset/Regressao/Treino/y_training.csv\")\n",
    "\n",
    "#Importando dados de validação\n",
    "x_val = pd.read_csv(\"../../dataset/Regressao/Validacao/X_validation.csv\")\n",
    "y_val = pd.read_csv(\"../../dataset/Regressao/Validacao/y_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Alpha: 0.01, Best Max Iter: 100, Best L1 Ratio: 0.9\n"
     ]
    }
   ],
   "source": [
    "#Escolha do melhor parâmetro\n",
    "\n",
    "alphas = [0.01, 0.1, 1, 10,20]\n",
    "max_iters = [100, 500, 1000, 2000]\n",
    "l1_ratios = [0.1, 0.5, 0.9]\n",
    "best_alpha = None\n",
    "best_score = float('inf')\n",
    "\n",
    "for alpha in alphas:\n",
    "    for max_iter in max_iters:\n",
    "        # Instanciar e treinar o modelo\n",
    "        elastic_net = ElasticNet(alpha=alpha, max_iter=max_iter,l1_ratio=l1_ratio, random_state=42)\n",
    "        elastic_net.fit(x_train, y_train)\n",
    "\n",
    "        # Avaliar no conjunto de validação\n",
    "        y_val_pred = elastic_net.predict(x_val)\n",
    "        score = mt.mean_squared_error(y_val, y_val_pred)\n",
    "\n",
    "        # Atualizar os melhores parâmetros\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_alpha = alpha\n",
    "            best_max_iter = max_iter\n",
    "            best_l1_ratio = l1_ratio\n",
    "\n",
    "print(f\"Best Alpha: {best_alpha}, Best Max Iter: {best_max_iter}, Best L1 Ratio: {best_l1_ratio}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treinamento do modelo\n",
    "elastic_net = ElasticNet(alpha=best_alpha,max_iter=best_max_iter,l1_ratio=best_l1_ratio, random_state=42)\n",
    "elastic_net.fit(x_train, y_train)\n",
    "\n",
    "#Previsão\n",
    "y_pred = elastic_net.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 3.99%\n",
      "MSE: 458.46\n",
      "RMSE: 21.411679056066575\n",
      "MAE: 17.036825630946176\n",
      "MAPE: 8.68449266421132\n"
     ]
    }
   ],
   "source": [
    "#Métricas de performance para dados de validação\n",
    "\n",
    "linear_regression_elastic_net_val_R2 = r2_squared_out_10 = np.round(100 * mt.r2_score(y_val, y_pred), 2)\n",
    "linear_regression_elastic_net_val_MSE = mse_out_10 = np.round(mt.mean_squared_error(y_val, y_pred), 2)\n",
    "linear_regression_elastic_net_val_RMSE = rmse_out_10 = np.sqrt(mse_out_10)\n",
    "linear_regression_elastic_net_val_MAE = mt.mean_absolute_error(y_val, y_pred)\n",
    "linear_regression_elastic_net_val_MAPE = mt.mean_absolute_percentage_error(y_val, y_pred)\n",
    "\n",
    "print(f\"R²: {linear_regression_elastic_net_val_R2}%\")\n",
    "print(f\"MSE: {linear_regression_elastic_net_val_MSE}\")\n",
    "print(f\"RMSE: {linear_regression_elastic_net_val_RMSE}\")\n",
    "print(f\"MAE: {linear_regression_elastic_net_val_MAE}\")\n",
    "print(f\"MAPE: {linear_regression_elastic_net_val_MAPE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobre os dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando dados de treinamento\n",
    "x_train = pd.read_csv(\"../../dataset/Regressao/Treino/X_training.csv\")\n",
    "y_train = pd.read_csv(\"../../dataset/Regressao/Treino/y_training.csv\")\n",
    "\n",
    "#Importando dados de validação\n",
    "x_val = pd.read_csv(\"../../dataset/Regressao/Validacao/X_validation.csv\")\n",
    "y_val = pd.read_csv(\"../../dataset/Regressao/Validacao/y_val.csv\")\n",
    "\n",
    "#Importando dados de teste\n",
    "x_test = pd.read_csv(\"../../dataset/Regressao/Teste/X_test.csv\")\n",
    "y_test = pd.read_csv(\"../../dataset/Regressao/Teste/y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Alpha: 0.01, Best Max Iter: 100, Best L1 Ratio: 0.9\n"
     ]
    }
   ],
   "source": [
    "#Escolha do melhor parâmetro\n",
    "\n",
    "alphas = [0.01, 0.1, 1, 10,20]\n",
    "max_iters = [100, 500, 1000, 2000]\n",
    "l1_ratios = [0.1, 0.5, 0.9]\n",
    "best_alpha = None\n",
    "best_score = float('inf')\n",
    "\n",
    "for alpha in alphas:\n",
    "    for max_iter in max_iters:\n",
    "        # Instanciar e treinar o modelo\n",
    "        elastic_net = ElasticNet(alpha=alpha, max_iter=max_iter,l1_ratio=l1_ratio, random_state=42)\n",
    "        elastic_net.fit(x_train, y_train)\n",
    "\n",
    "        # Avaliar no conjunto de validação\n",
    "        y_val_pred = elastic_net.predict(x_val)\n",
    "        score = mt.mean_squared_error(y_val, y_val_pred)\n",
    "\n",
    "        # Atualizar os melhores parâmetros\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_alpha = alpha\n",
    "            best_max_iter = max_iter\n",
    "            best_l1_ratio = l1_ratio\n",
    "\n",
    "print(f\"Best Alpha: {best_alpha}, Best Max Iter: {best_max_iter}, Best L1 Ratio: {best_l1_ratio}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treinamento do modelo\n",
    "elastic_net = ElasticNet(alpha=best_alpha, max_iter=best_max_iter,l1_ratio=best_l1_ratio, random_state=42)\n",
    "elastic_net.fit(x_train, y_train)\n",
    "\n",
    "#Previsão\n",
    "y_pred = elastic_net.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 3.99%\n",
      "MSE: 458.46\n",
      "RMSE: 21.411679056066575\n",
      "MAE: 17.036825630946176\n",
      "MAPE: 8.68449266421132\n"
     ]
    }
   ],
   "source": [
    "#Métricas de performance para dados de validação\n",
    "\n",
    "R2 = r2_squared_out_10 = np.round(100 * mt.r2_score(y_val, y_pred), 2)\n",
    "MSE = mse_out_10 = np.round(mt.mean_squared_error(y_val, y_pred), 2)\n",
    "RMSE = rmse_out_10 = np.sqrt(mse_out_10)\n",
    "MAE = mt.mean_absolute_error(y_val, y_pred)\n",
    "MAPE = mt.mean_absolute_percentage_error(y_val, y_pred)\n",
    "\n",
    "print(f\"R²: {R2}%\")\n",
    "print(f\"MSE: {MSE}\")\n",
    "print(f\"RMSE: {RMSE}\")\n",
    "print(f\"MAE: {MAE}\")\n",
    "print(f\"MAPE: {MAPE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:457: UserWarning: X has feature names, but ElasticNet was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Treinamento do modelo\n",
    "elastic_net = ElasticNet(alpha=best_alpha,max_iter=best_max_iter,l1_ratio=best_l1_ratio, random_state=42)\n",
    "elastic_net.fit(np.concatenate((x_train, x_val) ), np.concatenate((y_train, y_val)))\n",
    "\n",
    "#Previsão\n",
    "y_pred = elastic_net.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 5.06%\n",
      "MSE: 462.25\n",
      "RMSE: 21.5\n",
      "MAE: 17.144567486484593\n",
      "MAPE: 8.555132978757065\n"
     ]
    }
   ],
   "source": [
    "#Métricas de performance para dados de teste\n",
    "\n",
    "linear_regression_elastic_net_test_R2 = r2_squared_out_10 = np.round(100 * mt.r2_score(y_test, y_pred), 2)\n",
    "linear_regression_elastic_net_test_MSE = mse_out_10 = np.round(mt.mean_squared_error(y_test, y_pred), 2)\n",
    "linear_regression_elastic_net_test_RMSE = rmse_out_10 = np.sqrt(mse_out_10)\n",
    "linear_regression_elastic_net_test_MAE = mt.mean_absolute_error(y_test, y_pred)\n",
    "linear_regression_elastic_net_test_MAPE = mt.mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "print(f\"R²: {linear_regression_elastic_net_test_R2}%\")\n",
    "print(f\"MSE: {linear_regression_elastic_net_test_MSE}\")\n",
    "print(f\"RMSE: {linear_regression_elastic_net_test_RMSE}\")\n",
    "print(f\"MAE: {linear_regression_elastic_net_test_MAE}\")\n",
    "print(f\"MAPE: {linear_regression_elastic_net_test_MAPE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polinomial Regression Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics as mt\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobre dados de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando dados de treinamento\n",
    "x_train = pd.read_csv(\"../../dataset/Regressao/Treino/X_training.csv\")\n",
    "y_train = pd.read_csv(\"../../dataset/Regressao/Treino/y_training.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.452e+06, tolerance: 5.042e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor grau polinomial: 5\n"
     ]
    }
   ],
   "source": [
    "#Encontrar o melhor degree\n",
    "degrees = [1, 2, 3, 4, 5]  # Graus a serem testados\n",
    "errors = []  # Para armazenar erros \n",
    "\n",
    "for degree in degrees:\n",
    "    \n",
    "    # Transformar para características polinomiais\n",
    "    poly_features = PolynomialFeatures(degree=degree)\n",
    "    x_train_poly = poly_features.fit_transform(x_train)\n",
    "\n",
    "    # Treinar modelo\n",
    "    model = Lasso()\n",
    "    model.fit(x_train_poly, y_train)\n",
    "    \n",
    "    # Prever nos dados de treino\n",
    "    y_train_pred = model.predict(x_train_poly)\n",
    "    train_error = mt.mean_squared_error(y_train, y_train_pred)\n",
    "    errors.append(train_error)\n",
    "\n",
    "# Escolher o melhor grau\n",
    "best_degree = degrees[np.argmin(errors)]\n",
    "print(f\"Melhor grau polinomial: {best_degree}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "43 fits failed out of a total of 45.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 420, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 905, in fit\n",
      "    X, y = self._validate_data(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 621, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1147, in check_X_y\n",
      "    X = check_array(\n",
      "        ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 917, in check_array\n",
      "    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 380, in _asarray_with_order\n",
      "    array = numpy.asarray(array, order=order, dtype=dtype)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 460. MiB for an array with shape (7031, 8568) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 420, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 905, in fit\n",
      "    X, y = self._validate_data(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 621, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1147, in check_X_y\n",
      "    X = check_array(\n",
      "        ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 917, in check_array\n",
      "    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 380, in _asarray_with_order\n",
      "    array = numpy.asarray(array, order=order, dtype=dtype)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 460. MiB for an array with shape (7032, 8568) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 420, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1001, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "                                             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 628, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"sklearn\\linear_model\\_cd_fast.pyx\", line 135, in sklearn.linear_model._cd_fast.enet_coordinate_descent\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 460. MiB for an array with shape (7031, 8568) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 416, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 370, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 950, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 918, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "         ^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 460. MiB for an array with shape (7032, 8568) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "17 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 416, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 370, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 950, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 918, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "         ^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 460. MiB for an array with shape (7031, 8568) and data type float64\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor alpha: 0.01\n",
      "Melhor max_iter: 100\n",
      "Melhor erro (MSE): nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.210e+06, tolerance: 5.042e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "#Encontrar os melhores alphas e max_iter\n",
    "\n",
    "# Parâmetros para busca\n",
    "alphas = [0.01, 0.1, 1, 10, 100]\n",
    "max_iters = [100, 500, 1000]\n",
    "\n",
    "# Criar pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('poly_features', PolynomialFeatures(degree=best_degree)),  # Fixar o grau polinomial\n",
    "    ('lasso', Lasso(random_state=42))                           # Modelo de regressão Lasso\n",
    "])\n",
    "\n",
    "# Configurar o GridSearchCV\n",
    "param_grid = {\n",
    "    'lasso__alpha': alphas,\n",
    "    'lasso__max_iter': max_iters\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring='neg_mean_squared_error',  # Usar MSE como métrica\n",
    "    cv=3,                              # Validação cruzada com 3 divisões\n",
    "    n_jobs=-1,                         # Paralelização para maior velocidade\n",
    "    verbose=1                          # Exibir progresso\n",
    ")\n",
    "\n",
    "# Executar pesquisa de melhores parâmetros\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Armazenar os melhores parâmetros\n",
    "best_alpha = grid_search.best_params_['lasso__alpha']\n",
    "best_max_iter = grid_search.best_params_['lasso__max_iter']\n",
    "best_score = -grid_search.best_score_  # Negativo porque a métrica é negativa\n",
    "\n",
    "# Exibir os melhores parâmetros\n",
    "print(f\"Melhor alpha: {best_alpha}\")\n",
    "print(f\"Melhor max_iter: {best_max_iter}\")\n",
    "print(f\"Melhor erro (MSE): {best_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar para características polinomiais\n",
    "poly_features = PolynomialFeatures(degree=best_degree)\n",
    "x_train_poly = poly_features.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.210e+06, tolerance: 5.042e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# Treinar o modelo\n",
    "lasso = Lasso(alpha=best_alpha,max_iter=best_max_iter, random_state=42)\n",
    "lasso.fit(x_train_poly, y_train)\n",
    "\n",
    "# Previsão do algoritmo\n",
    "y_pred = lasso.predict(x_train_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 15.48%\n",
      "MSE: 404.02\n",
      "RMSE: 20.10024875467963\n",
      "MAE: 15.814546859656337\n",
      "MAPE: 7.824247430284007\n"
     ]
    }
   ],
   "source": [
    "#Métricas de performance para dados de treino\n",
    "\n",
    "polinomial_regression_lasso_train_R2 = r2_squared_out_10 = np.round(100 * mt.r2_score(y_train, y_pred), 2)\n",
    "polinomial_regression_lasso_train_MSE = mse_out_10 = np.round(mt.mean_squared_error(y_train, y_pred), 2)\n",
    "polinomial_regression_lasso_train_RMSE = rmse_out_10 = np.sqrt(mse_out_10)\n",
    "polinomial_regression_lasso_train_MAE = mt.mean_absolute_error(y_train, y_pred)\n",
    "polinomial_regression_lasso_train_MAPE = mt.mean_absolute_percentage_error(y_train, y_pred)\n",
    "\n",
    "print(f\"R²: {polinomial_regression_lasso_train_R2}%\")\n",
    "print(f\"MSE: {polinomial_regression_lasso_train_MSE}\")\n",
    "print(f\"RMSE: {polinomial_regression_lasso_train_RMSE}\")\n",
    "print(f\"MAE: {polinomial_regression_lasso_train_MAE}\")\n",
    "print(f\"MAPE: {polinomial_regression_lasso_train_MAPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobre dados de validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando dados de treinamento\n",
    "x_train = pd.read_csv(\"../../dataset/Regressao/Treino/X_training.csv\")\n",
    "y_train = pd.read_csv(\"../../dataset/Regressao/Treino/y_training.csv\")\n",
    "\n",
    "#Importando dados de validação\n",
    "x_val = pd.read_csv(\"../../dataset/Regressao/Validacao/X_validation.csv\")\n",
    "y_val = pd.read_csv(\"../../dataset/Regressao/Validacao/y_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor grau polinomial: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.452e+06, tolerance: 5.042e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "#Encontrar o melhor degree\n",
    "\n",
    "degrees = [1, 2, 3, 4, 5]  # Graus a serem testados\n",
    "validation_errors = []  # Para armazenar erros de validação\n",
    "\n",
    "for degree in degrees:\n",
    "    \n",
    "    # Transformar para características polinomiais\n",
    "    poly_features = PolynomialFeatures(degree=degree)\n",
    "    x_train_poly = poly_features.fit_transform(x_train)\n",
    "    x_val_poly = poly_features.transform(x_val)\n",
    "\n",
    "    # Treinar modelo\n",
    "    model = Lasso()\n",
    "    model.fit(x_train_poly, y_train)\n",
    "    \n",
    "    # Prever nos dados de validação\n",
    "    y_val_pred = model.predict(x_val_poly)\n",
    "    val_error = mt.mean_squared_error(y_val, y_val_pred)\n",
    "    validation_errors.append(val_error)\n",
    "\n",
    "# Escolher o melhor grau\n",
    "best_degree = degrees[np.argmin(validation_errors)]\n",
    "print(f\"Melhor grau polinomial: {best_degree}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "Melhor alpha: 0.1\n",
      "Melhor max_iter: 100\n",
      "Melhor erro (MSE): 453.33171919982277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.524e+05, tolerance: 5.042e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "#Encontrar os melhores alphas e max_iter\n",
    "\n",
    "# Parâmetros para busca\n",
    "alphas = [0.01, 0.1, 1, 10, 100]\n",
    "max_iters = [100, 500, 1000]\n",
    "\n",
    "# Criar pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('poly_features', PolynomialFeatures(degree=best_degree)),  # Fixar o grau polinomial\n",
    "    ('lasso', Lasso(random_state=42))                           # Modelo de regressão Lasso\n",
    "])\n",
    "\n",
    "# Configurar o GridSearchCV\n",
    "param_grid = {\n",
    "    'lasso__alpha': alphas,\n",
    "    'lasso__max_iter': max_iters\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring='neg_mean_squared_error',  # Usar MSE como métrica\n",
    "    cv=3,                              # Validação cruzada com 3 divisões\n",
    "    n_jobs=-1,                         # Paralelização para maior velocidade\n",
    "    verbose=1                          # Exibir progresso\n",
    ")\n",
    "\n",
    "# Executar pesquisa de melhores parâmetros\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Armazenar os melhores parâmetros\n",
    "best_alpha = grid_search.best_params_['lasso__alpha']\n",
    "best_max_iter = grid_search.best_params_['lasso__max_iter']\n",
    "best_score = -grid_search.best_score_  # Negativo porque a métrica é negativa\n",
    "\n",
    "# Exibir os melhores parâmetros\n",
    "print(f\"Melhor alpha: {best_alpha}\")\n",
    "print(f\"Melhor max_iter: {best_max_iter}\")\n",
    "print(f\"Melhor erro (MSE): {best_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar para características polinomiais\n",
    "poly_features = PolynomialFeatures(degree=best_degree)\n",
    "x_train_poly = poly_features.fit_transform(x_train)\n",
    "x_val_poly = poly_features.transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.524e+05, tolerance: 5.042e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# Treinar o modelo\n",
    "lasso = Lasso(alpha=best_alpha,max_iter=best_max_iter, random_state=42)\n",
    "lasso.fit(x_train_poly, y_train)\n",
    "\n",
    "# Previsão do algoritmo\n",
    "y_pred = lasso.predict(x_val_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 5.87%\n",
      "MSE: 449.47\n",
      "RMSE: 21.20070753536306\n",
      "MAE: 16.815513044531368\n",
      "MAPE: 8.625964900192926\n"
     ]
    }
   ],
   "source": [
    "#Métricas de performance para dados de validação\n",
    "\n",
    "polinomial_regression_lasso_val_R2 = r2_squared_out_10 = np.round(100 * mt.r2_score(y_val, y_pred), 2)\n",
    "polinomial_regression_lasso_val_MSE = mse_out_10 = np.round(mt.mean_squared_error(y_val, y_pred), 2)\n",
    "polinomial_regression_lasso_val_RMSE = rmse_out_10 = np.sqrt(mse_out_10)\n",
    "polinomial_regression_lasso_val_MAE = mt.mean_absolute_error(y_val, y_pred)\n",
    "polinomial_regression_lasso_val_MAPE = mt.mean_absolute_percentage_error(y_val, y_pred)\n",
    "\n",
    "print(f\"R²: {polinomial_regression_lasso_val_R2}%\")\n",
    "print(f\"MSE: {polinomial_regression_lasso_val_MSE}\")\n",
    "print(f\"RMSE: {polinomial_regression_lasso_val_RMSE}\")\n",
    "print(f\"MAE: {polinomial_regression_lasso_val_MAE}\")\n",
    "print(f\"MAPE: {polinomial_regression_lasso_val_MAPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobre dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando dados de treinamento\n",
    "x_train = pd.read_csv(\"../../dataset/Regressao/Treino/X_training.csv\")\n",
    "y_train = pd.read_csv(\"../../dataset/Regressao/Treino/y_training.csv\")\n",
    "\n",
    "#Importando dados de validação\n",
    "x_val = pd.read_csv(\"../../dataset/Regressao/Validacao/X_validation.csv\")\n",
    "y_val = pd.read_csv(\"../../dataset/Regressao/Validacao/y_val.csv\")\n",
    "\n",
    "#Importando dados de teste\n",
    "x_test = pd.read_csv(\"../../dataset/Regressao/Teste/X_test.csv\")\n",
    "y_test = pd.read_csv(\"../../dataset/Regressao/Teste/y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor grau polinomial: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.452e+06, tolerance: 5.042e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "#Encontrar o melhor degree\n",
    "degrees = [1, 2, 3, 4, 5]  # Graus a serem testados\n",
    "validation_errors = []  # Para armazenar erros de validação\n",
    "\n",
    "for degree in degrees:\n",
    "    \n",
    "    # Transformar para características polinomiais\n",
    "    poly_features = PolynomialFeatures(degree=degree)\n",
    "    x_train_poly = poly_features.fit_transform(x_train)\n",
    "    x_val_poly = poly_features.transform(x_val)\n",
    "\n",
    "    # Treinar modelo\n",
    "    model = Lasso()\n",
    "    model.fit(x_train_poly, y_train)\n",
    "    \n",
    "    # Prever nos dados de validação\n",
    "    y_val_pred = model.predict(x_val_poly)\n",
    "    val_error = mt.mean_squared_error(y_val, y_val_pred)\n",
    "    validation_errors.append(val_error)\n",
    "\n",
    "# Escolher o melhor grau\n",
    "best_degree = degrees[np.argmin(validation_errors)]\n",
    "print(f\"Melhor grau polinomial: {best_degree}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "Melhor alpha: 0.1\n",
      "Melhor max_iter: 100\n",
      "Melhor erro (MSE): 453.33171919982277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.524e+05, tolerance: 5.042e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "#Encontrar os melhores alphas e max_iter\n",
    "\n",
    "# Parâmetros para busca\n",
    "alphas = [0.01, 0.1, 1, 10, 100]\n",
    "max_iters = [100, 500, 1000]\n",
    "\n",
    "# Criar pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('poly_features', PolynomialFeatures(degree=best_degree)),  # Fixar o grau polinomial\n",
    "    ('lasso', Lasso(random_state=42))                           # Modelo de regressão Lasso\n",
    "])\n",
    "\n",
    "# Configurar o GridSearchCV\n",
    "param_grid = {\n",
    "    'lasso__alpha': alphas,\n",
    "    'lasso__max_iter': max_iters\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring='neg_mean_squared_error',  # Usar MSE como métrica\n",
    "    cv=3,                              # Validação cruzada com 3 divisões\n",
    "    n_jobs=-1,                         # Paralelização para maior velocidade\n",
    "    verbose=1                          # Exibir progresso\n",
    ")\n",
    "\n",
    "# Executar pesquisa de melhores parâmetros\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Armazenar os melhores parâmetros\n",
    "best_alpha = grid_search.best_params_['lasso__alpha']\n",
    "best_max_iter = grid_search.best_params_['lasso__max_iter']\n",
    "best_score = -grid_search.best_score_  # Negativo porque a métrica é negativa\n",
    "\n",
    "# Exibir os melhores parâmetros\n",
    "print(f\"Melhor alpha: {best_alpha}\")\n",
    "print(f\"Melhor max_iter: {best_max_iter}\")\n",
    "print(f\"Melhor erro (MSE): {best_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar para características polinomiais\n",
    "poly_features = PolynomialFeatures(degree=best_degree)\n",
    "x_train_poly = poly_features.fit_transform(x_train)\n",
    "x_val_poly = poly_features.transform(x_val)\n",
    "x_test_poly = poly_features.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.524e+05, tolerance: 5.042e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# Treinar o modelo\n",
    "lasso = Lasso(alpha=best_alpha,max_iter=best_max_iter, random_state=42)\n",
    "lasso.fit(x_train_poly, y_train)\n",
    "\n",
    "# Previsão do algoritmo\n",
    "y_pred = lasso.predict(x_val_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 5.87%\n",
      "MSE: 449.47\n",
      "RMSE: 21.20070753536306\n",
      "MAE: 16.815513044531368\n",
      "MAPE: 8.625964900192926\n"
     ]
    }
   ],
   "source": [
    "#Métricas de performance para dados de validação\n",
    "\n",
    "R2 = r2_squared_out_10 = np.round(100 * mt.r2_score(y_val, y_pred), 2)\n",
    "MSE = mse_out_10 = np.round(mt.mean_squared_error(y_val, y_pred), 2)\n",
    "RMSE = rmse_out_10 = np.sqrt(mse_out_10)\n",
    "MAE = mt.mean_absolute_error(y_val, y_pred)\n",
    "MAPE = mt.mean_absolute_percentage_error(y_val, y_pred)\n",
    "\n",
    "print(f\"R²: {R2}%\")\n",
    "print(f\"MSE: {MSE}\")\n",
    "print(f\"RMSE: {RMSE}\")\n",
    "print(f\"MAE: {MAE}\")\n",
    "print(f\"MAPE: {MAPE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.414e+06, tolerance: 7.200e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# Treinar o modelo\n",
    "lasso = Lasso(alpha=best_alpha,max_iter=best_max_iter, random_state=42)\n",
    "lasso.fit(np.concatenate((x_train_poly, x_val_poly) ), np.concatenate((y_train, y_val)))\n",
    "\n",
    "# Previsão do algoritmo\n",
    "y_pred = lasso.predict(x_test_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 7.66%\n",
      "MSE: 449.6\n",
      "RMSE: 21.203773249117717\n",
      "MAE: 16.84439303203739\n",
      "MAPE: 8.441402522227365\n"
     ]
    }
   ],
   "source": [
    "#Métricas de performance para dados de teste\n",
    "\n",
    "polinomial_regression_lasso_test_R2 = r2_squared_out_10 = np.round(100 * mt.r2_score(y_test, y_pred), 2)\n",
    "polinomial_regression_lasso_test_MSE = mse_out_10 = np.round(mt.mean_squared_error(y_test, y_pred), 2)\n",
    "polinomial_regression_lasso_test_RMSE = rmse_out_10 = np.sqrt(mse_out_10)\n",
    "polinomial_regression_lasso_test_MAE = mt.mean_absolute_error(y_test, y_pred)\n",
    "polinomial_regression_lasso_test_MAPE = mt.mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "print(f\"R²: {polinomial_regression_lasso_test_R2}%\")\n",
    "print(f\"MSE: {polinomial_regression_lasso_test_MSE}\")\n",
    "print(f\"RMSE: {polinomial_regression_lasso_test_RMSE}\")\n",
    "print(f\"MAE: {polinomial_regression_lasso_test_MAE}\")\n",
    "print(f\"MAPE: {polinomial_regression_lasso_test_MAPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polinomial Regression Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics as mt\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobre dados de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando dados de treinamento\n",
    "x_train = pd.read_csv(\"../../dataset/Regressao/Treino/X_training.csv\")\n",
    "y_train = pd.read_csv(\"../../dataset/Regressao/Treino/y_training.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor grau polinomial: 5\n"
     ]
    }
   ],
   "source": [
    "#Encontrar o melhor degree\n",
    "degrees = [1, 2, 3, 4, 5]  # Graus a serem testados\n",
    "errors = []  # Para armazenar erros \n",
    "\n",
    "for degree in degrees:\n",
    "    \n",
    "    # Transformar para características polinomiais\n",
    "    poly_features = PolynomialFeatures(degree=degree)\n",
    "    x_train_poly = poly_features.fit_transform(x_train)\n",
    "\n",
    "    # Treinar modelo\n",
    "    model = Ridge()\n",
    "    model.fit(x_train_poly, y_train)\n",
    "    \n",
    "    # Prever nos dados de treino\n",
    "    y_train_pred = model.predict(x_train_poly)\n",
    "    train_error = mt.mean_squared_error(y_train, y_train_pred)\n",
    "    errors.append(train_error)\n",
    "\n",
    "# Escolher o melhor grau\n",
    "best_degree = degrees[np.argmin(errors)]\n",
    "print(f\"Melhor grau polinomial: {best_degree}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "43 fits failed out of a total of 45.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 420, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 1142, in fit\n",
      "    return super().fit(X, y, sample_weight=sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 860, in fit\n",
      "    X, y, X_offset, y_offset, X_scale = _preprocess_data(\n",
      "                                        ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 238, in _preprocess_data\n",
      "    X = check_array(X, copy=copy, accept_sparse=[\"csr\", \"csc\"], dtype=FLOAT_DTYPES)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 988, in check_array\n",
      "    array = _asarray_with_order(\n",
      "            ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 378, in _asarray_with_order\n",
      "    array = numpy.array(array, order=order, dtype=dtype)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 460. MiB for an array with shape (7031, 8568) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 420, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 1142, in fit\n",
      "    return super().fit(X, y, sample_weight=sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 860, in fit\n",
      "    X, y, X_offset, y_offset, X_scale = _preprocess_data(\n",
      "                                        ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 238, in _preprocess_data\n",
      "    X = check_array(X, copy=copy, accept_sparse=[\"csr\", \"csc\"], dtype=FLOAT_DTYPES)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 988, in check_array\n",
      "    array = _asarray_with_order(\n",
      "            ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 378, in _asarray_with_order\n",
      "    array = numpy.array(array, order=order, dtype=dtype)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 460. MiB for an array with shape (7032, 8568) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 420, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 1142, in fit\n",
      "    return super().fit(X, y, sample_weight=sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 894, in fit\n",
      "    self.coef_, self.n_iter_ = _ridge_regression(\n",
      "                               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 694, in _ridge_regression\n",
      "    K = safe_sparse_dot(X, X.T, dense_output=True)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py\", line 193, in safe_sparse_dot\n",
      "    ret = a @ b\n",
      "          ~~^~~\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 377. MiB for an array with shape (7031, 7031) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 420, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 1142, in fit\n",
      "    return super().fit(X, y, sample_weight=sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 894, in fit\n",
      "    self.coef_, self.n_iter_ = _ridge_regression(\n",
      "                               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 694, in _ridge_regression\n",
      "    K = safe_sparse_dot(X, X.T, dense_output=True)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py\", line 193, in safe_sparse_dot\n",
      "    ret = a @ b\n",
      "          ~~^~~\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 377. MiB for an array with shape (7032, 7032) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "18 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 416, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 370, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 950, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 918, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "         ^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 460. MiB for an array with shape (7031, 8568) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 416, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 370, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 950, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 918, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "         ^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 460. MiB for an array with shape (7032, 8568) and data type float64\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor alpha: 0.01\n",
      "Melhor max_iter: 100\n",
      "Melhor erro (MSE): nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=5.00993e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    }
   ],
   "source": [
    "#Encontrar os melhores alphas e max_iter\n",
    "\n",
    "# Parâmetros para busca\n",
    "alphas = [0.01, 0.1, 1, 10, 100]\n",
    "max_iters = [100, 500, 1000]\n",
    "\n",
    "# Criar pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('poly_features', PolynomialFeatures(degree=best_degree)),  # Fixar o grau polinomial\n",
    "    ('ridge', Ridge(random_state=42))                           # Modelo de regressão Ridge\n",
    "])\n",
    "\n",
    "# Configurar o GridSearchCV\n",
    "param_grid = {\n",
    "    'ridge__alpha': alphas,\n",
    "    'ridge__max_iter': max_iters\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring='neg_mean_squared_error',  # Usar MSE como métrica\n",
    "    cv=3,                              # Validação cruzada com 3 divisões\n",
    "    n_jobs=-1,                         # Paralelização para maior velocidade\n",
    "    verbose=1                          # Exibir progresso\n",
    ")\n",
    "\n",
    "# Executar pesquisa de melhores parâmetros\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Armazenar os melhores parâmetros\n",
    "best_alpha = grid_search.best_params_['ridge__alpha']\n",
    "best_max_iter = grid_search.best_params_['ridge__max_iter']\n",
    "best_score = -grid_search.best_score_  # Negativo porque a métrica é negativa\n",
    "\n",
    "# Exibir os melhores parâmetros\n",
    "print(f\"Melhor alpha: {best_alpha}\")\n",
    "print(f\"Melhor max_iter: {best_max_iter}\")\n",
    "print(f\"Melhor erro (MSE): {best_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar para características polinomiais\n",
    "poly_features = PolynomialFeatures(degree=best_degree)\n",
    "x_train_poly = poly_features.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=5.00993e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    }
   ],
   "source": [
    "# Treinar o modelo\n",
    "ridge = Ridge(alpha=best_alpha,max_iter=best_max_iter, random_state=42)\n",
    "ridge.fit(x_train_poly, y_train)\n",
    "\n",
    "# Previsão do algoritmo\n",
    "y_pred = ridge.predict(x_train_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 47.56%\n",
      "MSE: 250.65\n",
      "RMSE: 15.831929762350514\n",
      "MAE: 11.749772281337087\n",
      "MAPE: 5.022674659783797\n"
     ]
    }
   ],
   "source": [
    "#Métricas de performance para dados de treino\n",
    "\n",
    "polinomial_regression_ridge_train_R2 = r2_squared_out_10 = np.round(100 * mt.r2_score(y_train, y_pred), 2)\n",
    "polinomial_regression_ridge_train_MSE = mse_out_10 = np.round(mt.mean_squared_error(y_train, y_pred), 2)\n",
    "polinomial_regression_ridge_train_RMSE = rmse_out_10 = np.sqrt(mse_out_10)\n",
    "polinomial_regression_ridge_train_MAE = mt.mean_absolute_error(y_train, y_pred)\n",
    "polinomial_regression_ridge_train_MAPE = mt.mean_absolute_percentage_error(y_train, y_pred)\n",
    "\n",
    "print(f\"R²: {polinomial_regression_ridge_train_R2}%\")\n",
    "print(f\"MSE: {polinomial_regression_ridge_train_MSE}\")\n",
    "print(f\"RMSE: {polinomial_regression_ridge_train_RMSE}\")\n",
    "print(f\"MAE: {polinomial_regression_ridge_train_MAE}\")\n",
    "print(f\"MAPE: {polinomial_regression_ridge_train_MAPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobre dados de validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando dados de treinamento\n",
    "x_train = pd.read_csv(\"../../dataset/Regressao/Treino/X_training.csv\")\n",
    "y_train = pd.read_csv(\"../../dataset/Regressao/Treino/y_training.csv\")\n",
    "\n",
    "#Importando dados de validação\n",
    "x_val = pd.read_csv(\"../../dataset/Regressao/Validacao/X_validation.csv\")\n",
    "y_val = pd.read_csv(\"../../dataset/Regressao/Validacao/y_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor grau polinomial: 2\n"
     ]
    }
   ],
   "source": [
    "#Encontrar o melhor degree\n",
    "\n",
    "degrees = [1, 2, 3, 4, 5]  # Graus a serem testados\n",
    "validation_errors = []  # Para armazenar erros de validação\n",
    "\n",
    "for degree in degrees:\n",
    "    \n",
    "    # Transformar para características polinomiais\n",
    "    poly_features = PolynomialFeatures(degree=degree)\n",
    "    x_train_poly = poly_features.fit_transform(x_train)\n",
    "    x_val_poly = poly_features.transform(x_val)\n",
    "\n",
    "    # Treinar modelo\n",
    "    model = Ridge()\n",
    "    model.fit(x_train_poly, y_train)\n",
    "    \n",
    "    # Prever nos dados de validação\n",
    "    y_val_pred = model.predict(x_val_poly)\n",
    "    val_error = mt.mean_squared_error(y_val, y_val_pred)\n",
    "    validation_errors.append(val_error)\n",
    "\n",
    "# Escolher o melhor grau\n",
    "best_degree = degrees[np.argmin(validation_errors)]\n",
    "print(f\"Melhor grau polinomial: {best_degree}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "Melhor alpha: 1\n",
      "Melhor max_iter: 100\n",
      "Melhor erro (MSE): 443.1435073686537\n"
     ]
    }
   ],
   "source": [
    "#Encontrar os melhores alphas e max_iter\n",
    "\n",
    "# Parâmetros para busca\n",
    "alphas = [0.01, 0.1, 1, 10, 100]\n",
    "max_iters = [100, 500, 1000]\n",
    "\n",
    "# Criar pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('poly_features', PolynomialFeatures(degree=best_degree)),  # Fixar o grau polinomial\n",
    "    ('ridge', Ridge(random_state=42))                           # Modelo de regressão Ridge\n",
    "])\n",
    "\n",
    "# Configurar o GridSearchCV\n",
    "param_grid = {\n",
    "    'ridge__alpha': alphas,\n",
    "    'ridge__max_iter': max_iters\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring='neg_mean_squared_error',  # Usar MSE como métrica\n",
    "    cv=3,                              # Validação cruzada com 3 divisões\n",
    "    n_jobs=-1,                         # Paralelização para maior velocidade\n",
    "    verbose=1                          # Exibir progresso\n",
    ")\n",
    "\n",
    "# Executar pesquisa de melhores parâmetros\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Armazenar os melhores parâmetros\n",
    "best_alpha = grid_search.best_params_['ridge__alpha']\n",
    "best_max_iter = grid_search.best_params_['ridge__max_iter']\n",
    "best_score = -grid_search.best_score_  # Negativo porque a métrica é negativa\n",
    "\n",
    "# Exibir os melhores parâmetros\n",
    "print(f\"Melhor alpha: {best_alpha}\")\n",
    "print(f\"Melhor max_iter: {best_max_iter}\")\n",
    "print(f\"Melhor erro (MSE): {best_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar para características polinomiais\n",
    "poly_features = PolynomialFeatures(degree=best_degree)\n",
    "x_train_poly = poly_features.fit_transform(x_train)\n",
    "x_val_poly = poly_features.transform(x_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar o modelo\n",
    "ridge = Ridge(alpha=best_alpha,max_iter=best_max_iter, random_state=42)\n",
    "ridge.fit(x_train_poly, y_train)\n",
    "\n",
    "# Previsão do algoritmo\n",
    "y_pred = ridge.predict(x_val_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 6.77%\n",
      "MSE: 445.18\n",
      "RMSE: 21.099289087549845\n",
      "MAE: 16.738740611690584\n",
      "MAPE: 8.568992470935276\n"
     ]
    }
   ],
   "source": [
    "#Métricas de performance para dados de validação\n",
    "\n",
    "polinomial_regression_ridge_val_R2 = r2_squared_out_10 = np.round(100 * mt.r2_score(y_val, y_pred), 2)\n",
    "polinomial_regression_ridge_val_MSE = mse_out_10 = np.round(mt.mean_squared_error(y_val, y_pred), 2)\n",
    "polinomial_regression_ridge_val_RMSE = rmse_out_10 = np.sqrt(mse_out_10)\n",
    "polinomial_regression_ridge_val_MAE = mt.mean_absolute_error(y_val, y_pred)\n",
    "polinomial_regression_ridge_val_MAPE = mt.mean_absolute_percentage_error(y_val, y_pred)\n",
    "\n",
    "print(f\"R²: {polinomial_regression_ridge_val_R2}%\")\n",
    "print(f\"MSE: {polinomial_regression_ridge_val_MSE}\")\n",
    "print(f\"RMSE: {polinomial_regression_ridge_val_RMSE}\")\n",
    "print(f\"MAE: {polinomial_regression_ridge_val_MAE}\")\n",
    "print(f\"MAPE: {polinomial_regression_ridge_val_MAPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobre dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando dados de treinamento\n",
    "x_train = pd.read_csv(\"../../dataset/Regressao/Treino/X_training.csv\")\n",
    "y_train = pd.read_csv(\"../../dataset/Regressao/Treino/y_training.csv\")\n",
    "\n",
    "#Importando dados de validação\n",
    "x_val = pd.read_csv(\"../../dataset/Regressao/Validacao/X_validation.csv\")\n",
    "y_val = pd.read_csv(\"../../dataset/Regressao/Validacao/y_val.csv\")\n",
    "\n",
    "#Importando dados de teste\n",
    "x_test = pd.read_csv(\"../../dataset/Regressao/Teste/X_test.csv\")\n",
    "y_test = pd.read_csv(\"../../dataset/Regressao/Teste/y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor grau polinomial: 2\n"
     ]
    }
   ],
   "source": [
    "#Encontrar o melhor degree\n",
    "degrees = [1, 2, 3, 4, 5]  # Graus a serem testados\n",
    "validation_errors = []  # Para armazenar erros de validação\n",
    "\n",
    "for degree in degrees:\n",
    "    \n",
    "    # Transformar para características polinomiais\n",
    "    poly_features = PolynomialFeatures(degree=degree)\n",
    "    x_train_poly = poly_features.fit_transform(x_train)\n",
    "    x_val_poly = poly_features.transform(x_val)\n",
    "\n",
    "    # Treinar modelo\n",
    "    model = Ridge()\n",
    "    model.fit(x_train_poly, y_train)\n",
    "    \n",
    "    # Prever nos dados de validação\n",
    "    y_val_pred = model.predict(x_val_poly)\n",
    "    val_error = mt.mean_squared_error(y_val, y_val_pred)\n",
    "    validation_errors.append(val_error)\n",
    "\n",
    "# Escolher o melhor grau\n",
    "best_degree = degrees[np.argmin(validation_errors)]\n",
    "print(f\"Melhor grau polinomial: {best_degree}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "Melhor alpha: 1\n",
      "Melhor max_iter: 100\n",
      "Melhor erro (MSE): 443.1435073686537\n"
     ]
    }
   ],
   "source": [
    "#Encontrar os melhores alphas e max_iter\n",
    "\n",
    "# Parâmetros para busca\n",
    "alphas = [0.01, 0.1, 1, 10, 100]\n",
    "max_iters = [100, 500, 1000]\n",
    "\n",
    "# Criar pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('poly_features', PolynomialFeatures(degree=best_degree)),  # Fixar o grau polinomial\n",
    "    ('ridge', Ridge(random_state=42))                           # Modelo de regressão Ridge\n",
    "])\n",
    "\n",
    "# Configurar o GridSearchCV\n",
    "param_grid = {\n",
    "    'ridge__alpha': alphas,\n",
    "    'ridge__max_iter': max_iters\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring='neg_mean_squared_error',  # Usar MSE como métrica\n",
    "    cv=3,                              # Validação cruzada com 3 divisões\n",
    "    n_jobs=-1,                         # Paralelização para maior velocidade\n",
    "    verbose=1                          # Exibir progresso\n",
    ")\n",
    "\n",
    "# Executar pesquisa de melhores parâmetros\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Armazenar os melhores parâmetros\n",
    "best_alpha = grid_search.best_params_['ridge__alpha']\n",
    "best_max_iter = grid_search.best_params_['ridge__max_iter']\n",
    "best_score = -grid_search.best_score_  # Negativo porque a métrica é negativa\n",
    "\n",
    "# Exibir os melhores parâmetros\n",
    "print(f\"Melhor alpha: {best_alpha}\")\n",
    "print(f\"Melhor max_iter: {best_max_iter}\")\n",
    "print(f\"Melhor erro (MSE): {best_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar para características polinomiais\n",
    "poly_features = PolynomialFeatures(degree=best_degree)\n",
    "x_train_poly = poly_features.fit_transform(x_train)\n",
    "x_val_poly = poly_features.transform(x_val)\n",
    "x_test_poly = poly_features.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar o modelo\n",
    "ridge = Ridge(alpha=best_alpha,max_iter=best_max_iter, random_state=42)\n",
    "ridge.fit(x_train_poly, y_train)\n",
    "\n",
    "# Previsão do algoritmo\n",
    "y_pred = ridge.predict(x_val_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 6.77%\n",
      "MSE: 445.18\n",
      "RMSE: 21.099289087549845\n",
      "MAE: 16.738740611690584\n",
      "MAPE: 8.568992470935276\n"
     ]
    }
   ],
   "source": [
    "#Métricas de performance para dados de validação\n",
    "\n",
    "R2 = r2_squared_out_10 = np.round(100 * mt.r2_score(y_val, y_pred), 2)\n",
    "MSE = mse_out_10 = np.round(mt.mean_squared_error(y_val, y_pred), 2)\n",
    "RMSE = rmse_out_10 = np.sqrt(mse_out_10)\n",
    "MAE = mt.mean_absolute_error(y_val, y_pred)\n",
    "MAPE = mt.mean_absolute_percentage_error(y_val, y_pred)\n",
    "\n",
    "print(f\"R²: {R2}%\")\n",
    "print(f\"MSE: {MSE}\")\n",
    "print(f\"RMSE: {RMSE}\")\n",
    "print(f\"MAE: {MAE}\")\n",
    "print(f\"MAPE: {MAPE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar o modelo\n",
    "ridge = Ridge(alpha=best_alpha,max_iter=best_max_iter, random_state=42)\n",
    "ridge.fit(np.concatenate((x_train_poly, x_val_poly) ), np.concatenate((y_train, y_val)))\n",
    "\n",
    "# Previsão do algoritmo\n",
    "y_pred = ridge.predict(x_test_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 9.02%\n",
      "MSE: 442.97\n",
      "RMSE: 21.046852496276017\n",
      "MAE: 16.74221387846808\n",
      "MAPE: 8.308500709997727\n"
     ]
    }
   ],
   "source": [
    "#Métricas de performance para dados de teste\n",
    "\n",
    "polinomial_regression_ridge_test_R2 = r2_squared_out_10 = np.round(100 * mt.r2_score(y_test, y_pred), 2)\n",
    "polinomial_regression_ridge_test_MSE = mse_out_10 = np.round(mt.mean_squared_error(y_test, y_pred), 2)\n",
    "polinomial_regression_ridge_test_RMSE = rmse_out_10 = np.sqrt(mse_out_10)\n",
    "polinomial_regression_ridge_test_MAE = mt.mean_absolute_error(y_test, y_pred)\n",
    "polinomial_regression_ridge_test_MAPE = mt.mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "print(f\"R²: {polinomial_regression_ridge_test_R2}%\")\n",
    "print(f\"MSE: {polinomial_regression_ridge_test_MSE}\")\n",
    "print(f\"RMSE: {polinomial_regression_ridge_test_RMSE}\")\n",
    "print(f\"MAE: {polinomial_regression_ridge_test_MAE}\")\n",
    "print(f\"MAPE: {polinomial_regression_ridge_test_MAPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polinomial Regression Elastic Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics as mt\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobre dados de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando dados de treinamento\n",
    "x_train = pd.read_csv(\"../../dataset/Regressao/Treino/X_training.csv\")\n",
    "y_train = pd.read_csv(\"../../dataset/Regressao/Treino/y_training.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.189e+06, tolerance: 5.042e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.466e+06, tolerance: 5.042e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor grau polinomial: 5\n"
     ]
    }
   ],
   "source": [
    "#Encontrar o melhor degree\n",
    "degrees = [1, 2, 3, 4, 5]  # Graus a serem testados\n",
    "errors = []  # Para armazenar erros \n",
    "\n",
    "for degree in degrees:\n",
    "    \n",
    "    # Transformar para características polinomiais\n",
    "    poly_features = PolynomialFeatures(degree=degree)\n",
    "    x_train_poly = poly_features.fit_transform(x_train)\n",
    "\n",
    "    # Treinar modelo\n",
    "    model = ElasticNet()\n",
    "    model.fit(x_train_poly, y_train)\n",
    "    \n",
    "    # Prever nos dados de treino\n",
    "    y_train_pred = model.predict(x_train_poly)\n",
    "    train_error = mt.mean_squared_error(y_train, y_train_pred)\n",
    "    errors.append(train_error)\n",
    "\n",
    "# Escolher o melhor grau\n",
    "best_degree = degrees[np.argmin(errors)]\n",
    "print(f\"Melhor grau polinomial: {best_degree}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 45 candidates, totalling 135 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "132 fits failed out of a total of 135.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 420, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 905, in fit\n",
      "    X, y = self._validate_data(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 621, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1147, in check_X_y\n",
      "    X = check_array(\n",
      "        ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 917, in check_array\n",
      "    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 380, in _asarray_with_order\n",
      "    array = numpy.asarray(array, order=order, dtype=dtype)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 460. MiB for an array with shape (7031, 8568) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 420, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 905, in fit\n",
      "    X, y = self._validate_data(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 621, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1147, in check_X_y\n",
      "    X = check_array(\n",
      "        ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 917, in check_array\n",
      "    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 380, in _asarray_with_order\n",
      "    array = numpy.asarray(array, order=order, dtype=dtype)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 460. MiB for an array with shape (7032, 8568) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 420, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1001, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "                                             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 628, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"sklearn\\linear_model\\_cd_fast.pyx\", line 135, in sklearn.linear_model._cd_fast.enet_coordinate_descent\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 460. MiB for an array with shape (7031, 8568) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "39 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 416, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 370, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 950, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 918, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "         ^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 460. MiB for an array with shape (7032, 8568) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "76 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 416, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 370, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 950, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 918, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "         ^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 460. MiB for an array with shape (7031, 8568) and data type float64\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor alpha: 0.01\n",
      "Melhor max_iter: 100\n",
      "Melhor l1_ratio: 0.1\n",
      "Melhor erro (MSE): nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.162e+06, tolerance: 5.042e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# Encontrar os melhores alphas, max_iter e l1_ratio\n",
    "\n",
    "# Parâmetros para busca\n",
    "alphas = [0.01, 0.1, 1, 10, 100]\n",
    "max_iters = [100, 500, 1000]\n",
    "l1_ratios = [0.1, 0.5, 0.9]  # Valores representando diferentes proporções entre L1 e L2\n",
    "\n",
    "# Criar pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('poly_features', PolynomialFeatures(degree=best_degree)),  # Fixar o grau polinomial\n",
    "    ('elastic_net', ElasticNet(random_state=42))                # Modelo ElasticNet\n",
    "])\n",
    "\n",
    "# Configurar o GridSearchCV\n",
    "param_grid = {\n",
    "    'elastic_net__alpha': alphas,\n",
    "    'elastic_net__max_iter': max_iters,\n",
    "    'elastic_net__l1_ratio': l1_ratios\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring='neg_mean_squared_error',  # Usar MSE como métrica\n",
    "    cv=3,                              # Validação cruzada com 3 divisões\n",
    "    n_jobs=-1,                         # Paralelização para maior velocidade\n",
    "    verbose=1                          # Exibir progresso\n",
    ")\n",
    "\n",
    "# Executar pesquisa de melhores parâmetros\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Armazenar os melhores parâmetros\n",
    "best_alpha = grid_search.best_params_['elastic_net__alpha']\n",
    "best_max_iter = grid_search.best_params_['elastic_net__max_iter']\n",
    "best_l1_ratio = grid_search.best_params_['elastic_net__l1_ratio']\n",
    "best_score = -grid_search.best_score_  # Negativo porque a métrica é negativa\n",
    "\n",
    "# Exibir os melhores parâmetros\n",
    "print(f\"Melhor alpha: {best_alpha}\")\n",
    "print(f\"Melhor max_iter: {best_max_iter}\")\n",
    "print(f\"Melhor l1_ratio: {best_l1_ratio}\")\n",
    "print(f\"Melhor erro (MSE): {best_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar para características polinomiais\n",
    "poly_features = PolynomialFeatures(degree=best_degree)\n",
    "x_train_poly = poly_features.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.162e+06, tolerance: 5.042e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# Treinar o modelo\n",
    "elastic_net = ElasticNet(alpha=best_alpha,max_iter=best_max_iter,l1_ratio=best_l1_ratio, random_state=42)\n",
    "elastic_net.fit(x_train_poly, y_train)\n",
    "\n",
    "# Previsão do algoritmo\n",
    "y_pred = elastic_net.predict(x_train_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 16.59%\n",
      "MSE: 398.71\n",
      "RMSE: 19.967723956425278\n",
      "MAE: 15.693137309554475\n",
      "MAPE: 7.749604792749787\n"
     ]
    }
   ],
   "source": [
    "#Métricas de performance para dados de treino\n",
    "\n",
    "polinomial_regression_elastic_net_train_R2 = r2_squared_out_10 = np.round(100 * mt.r2_score(y_train, y_pred), 2)\n",
    "polinomial_regression_elastic_net_train_MSE = mse_out_10 = np.round(mt.mean_squared_error(y_train, y_pred), 2)\n",
    "polinomial_regression_elastic_net_train_RMSE = rmse_out_10 = np.sqrt(mse_out_10)\n",
    "polinomial_regression_elastic_net_train_MAE = mt.mean_absolute_error(y_train, y_pred)\n",
    "polinomial_regression_elastic_net_train_MAPE = mt.mean_absolute_percentage_error(y_train, y_pred)\n",
    "\n",
    "print(f\"R²: {polinomial_regression_elastic_net_train_R2}%\")\n",
    "print(f\"MSE: {polinomial_regression_elastic_net_train_MSE}\")\n",
    "print(f\"RMSE: {polinomial_regression_elastic_net_train_RMSE}\")\n",
    "print(f\"MAE: {polinomial_regression_elastic_net_train_MAE}\")\n",
    "print(f\"MAPE: {polinomial_regression_elastic_net_train_MAPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobre dados de validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando dados de treinamento\n",
    "x_train = pd.read_csv(\"../../dataset/Regressao/Treino/X_training.csv\")\n",
    "y_train = pd.read_csv(\"../../dataset/Regressao/Treino/y_training.csv\")\n",
    "\n",
    "#Importando dados de validação\n",
    "x_val = pd.read_csv(\"../../dataset/Regressao/Validacao/X_validation.csv\")\n",
    "y_val = pd.read_csv(\"../../dataset/Regressao/Validacao/y_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.189e+06, tolerance: 5.042e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor grau polinomial: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.466e+06, tolerance: 5.042e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "#Encontrar o melhor degree\n",
    "\n",
    "degrees = [1, 2, 3, 4, 5]  # Graus a serem testados\n",
    "validation_errors = []  # Para armazenar erros de validação\n",
    "\n",
    "for degree in degrees:\n",
    "    \n",
    "    # Transformar para características polinomiais\n",
    "    poly_features = PolynomialFeatures(degree=degree)\n",
    "    x_train_poly = poly_features.fit_transform(x_train)\n",
    "    x_val_poly = poly_features.transform(x_val)\n",
    "\n",
    "    # Treinar modelo\n",
    "    model = ElasticNet()\n",
    "    model.fit(x_train_poly, y_train)\n",
    "    \n",
    "    # Prever nos dados de validação\n",
    "    y_val_pred = model.predict(x_val_poly)\n",
    "    val_error = mt.mean_squared_error(y_val, y_val_pred)\n",
    "    validation_errors.append(val_error)\n",
    "\n",
    "# Escolher o melhor grau\n",
    "best_degree = degrees[np.argmin(validation_errors)]\n",
    "print(f\"Melhor grau polinomial: {best_degree}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 45 candidates, totalling 135 fits\n",
      "Melhor alpha: 0.1\n",
      "Melhor max_iter: 500\n",
      "Melhor l1_ratio: 0.9\n",
      "Melhor erro (MSE): 457.55305311123294\n"
     ]
    }
   ],
   "source": [
    "# Encontrar os melhores alphas, max_iter e l1_ratio\n",
    "\n",
    "# Parâmetros para busca\n",
    "alphas = [0.01, 0.1, 1, 10, 100]\n",
    "max_iters = [100, 500, 1000]\n",
    "l1_ratios = [0.1, 0.5, 0.9]  # Valores representando diferentes proporções entre L1 e L2\n",
    "\n",
    "# Criar pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('poly_features', PolynomialFeatures(degree=best_degree)),  # Fixar o grau polinomial\n",
    "    ('elastic_net', ElasticNet(random_state=42))                # Modelo ElasticNet\n",
    "])\n",
    "\n",
    "# Configurar o GridSearchCV\n",
    "param_grid = {\n",
    "    'elastic_net__alpha': alphas,\n",
    "    'elastic_net__max_iter': max_iters,\n",
    "    'elastic_net__l1_ratio': l1_ratios\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring='neg_mean_squared_error',  # Usar MSE como métrica\n",
    "    cv=3,                              # Validação cruzada com 3 divisões\n",
    "    n_jobs=-1,                         # Paralelização para maior velocidade\n",
    "    verbose=1                          # Exibir progresso\n",
    ")\n",
    "\n",
    "# Executar pesquisa de melhores parâmetros\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Armazenar os melhores parâmetros\n",
    "best_alpha = grid_search.best_params_['elastic_net__alpha']\n",
    "best_max_iter = grid_search.best_params_['elastic_net__max_iter']\n",
    "best_l1_ratio = grid_search.best_params_['elastic_net__l1_ratio']\n",
    "best_score = -grid_search.best_score_  # Negativo porque a métrica é negativa\n",
    "\n",
    "# Exibir os melhores parâmetros\n",
    "print(f\"Melhor alpha: {best_alpha}\")\n",
    "print(f\"Melhor max_iter: {best_max_iter}\")\n",
    "print(f\"Melhor l1_ratio: {best_l1_ratio}\")\n",
    "print(f\"Melhor erro (MSE): {best_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar para características polinomiais\n",
    "poly_features = PolynomialFeatures(degree=best_degree)\n",
    "x_train_poly = poly_features.fit_transform(x_train)\n",
    "x_val_poly = poly_features.transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar o modelo\n",
    "elastic_net = ElasticNet(alpha=best_alpha,max_iter=best_max_iter,l1_ratio=best_l1_ratio, random_state=42)\n",
    "elastic_net.fit(x_train_poly, y_train)\n",
    "\n",
    "# Previsão do algoritmo\n",
    "y_pred = elastic_net.predict(x_val_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 5.5%\n",
      "MSE: 451.25\n",
      "RMSE: 21.242645786248\n",
      "MAE: 16.830760948246596\n",
      "MAPE: 8.639837647336485\n"
     ]
    }
   ],
   "source": [
    "#Métricas de performance para dados de validação\n",
    "\n",
    "polinomial_regression_elastic_net_val_R2 = r2_squared_out_10 = np.round(100 * mt.r2_score(y_val, y_pred), 2)\n",
    "polinomial_regression_elastic_net_val_MSE = mse_out_10 = np.round(mt.mean_squared_error(y_val, y_pred), 2)\n",
    "polinomial_regression_elastic_net_val_RMSE = rmse_out_10 = np.sqrt(mse_out_10)\n",
    "polinomial_regression_elastic_net_val_MAE = mt.mean_absolute_error(y_val, y_pred)\n",
    "polinomial_regression_elastic_net_val_MAPE = mt.mean_absolute_percentage_error(y_val, y_pred)\n",
    "\n",
    "print(f\"R²: {polinomial_regression_elastic_net_val_R2}%\")\n",
    "print(f\"MSE: {polinomial_regression_elastic_net_val_MSE}\")\n",
    "print(f\"RMSE: {polinomial_regression_elastic_net_val_RMSE}\")\n",
    "print(f\"MAE: {polinomial_regression_elastic_net_val_MAE}\")\n",
    "print(f\"MAPE: {polinomial_regression_elastic_net_val_MAPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobre dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando dados de treinamento\n",
    "x_train = pd.read_csv(\"../../dataset/Regressao/Treino/X_training.csv\")\n",
    "y_train = pd.read_csv(\"../../dataset/Regressao/Treino/y_training.csv\")\n",
    "\n",
    "#Importando dados de validação\n",
    "x_val = pd.read_csv(\"../../dataset/Regressao/Validacao/X_validation.csv\")\n",
    "y_val = pd.read_csv(\"../../dataset/Regressao/Validacao/y_val.csv\")\n",
    "\n",
    "#Importando dados de teste\n",
    "x_test = pd.read_csv(\"../../dataset/Regressao/Teste/X_test.csv\")\n",
    "y_test = pd.read_csv(\"../../dataset/Regressao/Teste/y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.189e+06, tolerance: 5.042e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor grau polinomial: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lopes\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.466e+06, tolerance: 5.042e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "#Encontrar o melhor degree\n",
    "degrees = [1, 2, 3, 4, 5]  # Graus a serem testados\n",
    "validation_errors = []  # Para armazenar erros de validação\n",
    "\n",
    "for degree in degrees:\n",
    "    \n",
    "    # Transformar para características polinomiais\n",
    "    poly_features = PolynomialFeatures(degree=degree)\n",
    "    x_train_poly = poly_features.fit_transform(x_train)\n",
    "    x_val_poly = poly_features.transform(x_val)\n",
    "\n",
    "    # Treinar modelo\n",
    "    model = ElasticNet()\n",
    "    model.fit(x_train_poly, y_train)\n",
    "    \n",
    "    # Prever nos dados de validação\n",
    "    y_val_pred = model.predict(x_val_poly)\n",
    "    val_error = mt.mean_squared_error(y_val, y_val_pred)\n",
    "    validation_errors.append(val_error)\n",
    "\n",
    "# Escolher o melhor grau\n",
    "best_degree = degrees[np.argmin(validation_errors)]\n",
    "print(f\"Melhor grau polinomial: {best_degree}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 45 candidates, totalling 135 fits\n",
      "Melhor alpha: 0.1\n",
      "Melhor max_iter: 500\n",
      "Melhor l1_ratio: 0.9\n",
      "Melhor erro (MSE): 457.55305311123294\n"
     ]
    }
   ],
   "source": [
    "# Encontrar os melhores alphas, max_iter e l1_ratio\n",
    "\n",
    "# Parâmetros para busca\n",
    "alphas = [0.01, 0.1, 1, 10, 100]\n",
    "max_iters = [100, 500, 1000]\n",
    "l1_ratios = [0.1, 0.5, 0.9]  # Valores representando diferentes proporções entre L1 e L2\n",
    "\n",
    "# Criar pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('poly_features', PolynomialFeatures(degree=best_degree)),  # Fixar o grau polinomial\n",
    "    ('elastic_net', ElasticNet(random_state=42))                # Modelo ElasticNet\n",
    "])\n",
    "\n",
    "# Configurar o GridSearchCV\n",
    "param_grid = {\n",
    "    'elastic_net__alpha': alphas,\n",
    "    'elastic_net__max_iter': max_iters,\n",
    "    'elastic_net__l1_ratio': l1_ratios\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring='neg_mean_squared_error',  # Usar MSE como métrica\n",
    "    cv=3,                              # Validação cruzada com 3 divisões\n",
    "    n_jobs=-1,                         # Paralelização para maior velocidade\n",
    "    verbose=1                          # Exibir progresso\n",
    ")\n",
    "\n",
    "# Executar pesquisa de melhores parâmetros\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Armazenar os melhores parâmetros\n",
    "best_alpha = grid_search.best_params_['elastic_net__alpha']\n",
    "best_max_iter = grid_search.best_params_['elastic_net__max_iter']\n",
    "best_l1_ratio = grid_search.best_params_['elastic_net__l1_ratio']\n",
    "best_score = -grid_search.best_score_  # Negativo porque a métrica é negativa\n",
    "\n",
    "# Exibir os melhores parâmetros\n",
    "print(f\"Melhor alpha: {best_alpha}\")\n",
    "print(f\"Melhor max_iter: {best_max_iter}\")\n",
    "print(f\"Melhor l1_ratio: {best_l1_ratio}\")\n",
    "print(f\"Melhor erro (MSE): {best_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar para características polinomiais\n",
    "poly_features = PolynomialFeatures(degree=best_degree)\n",
    "x_train_poly = poly_features.fit_transform(x_train)\n",
    "x_val_poly = poly_features.transform(x_val)\n",
    "x_test_poly = poly_features.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar o modelo\n",
    "elastic_net = ElasticNet(alpha=best_alpha,max_iter=best_max_iter,l1_ratio=best_l1_ratio, random_state=42)\n",
    "elastic_net.fit(x_train_poly, y_train)\n",
    "\n",
    "# Previsão do algoritmo\n",
    "y_pred = elastic_net.predict(x_val_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 5.5%\n",
      "MSE: 451.25\n",
      "RMSE: 21.242645786248\n",
      "MAE: 16.830760948246596\n",
      "MAPE: 8.639837647336485\n"
     ]
    }
   ],
   "source": [
    "#Métricas de performance para dados de validação\n",
    "\n",
    "R2 = r2_squared_out_10 = np.round(100 * mt.r2_score(y_val, y_pred), 2)\n",
    "MSE = mse_out_10 = np.round(mt.mean_squared_error(y_val, y_pred), 2)\n",
    "RMSE = rmse_out_10 = np.sqrt(mse_out_10)\n",
    "MAE = mt.mean_absolute_error(y_val, y_pred)\n",
    "MAPE = mt.mean_absolute_percentage_error(y_val, y_pred)\n",
    "\n",
    "print(f\"R²: {R2}%\")\n",
    "print(f\"MSE: {MSE}\")\n",
    "print(f\"RMSE: {RMSE}\")\n",
    "print(f\"MAE: {MAE}\")\n",
    "print(f\"MAPE: {MAPE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar o modelo\n",
    "elastic_net = ElasticNet(alpha=best_alpha,max_iter=best_max_iter,l1_ratio=best_l1_ratio, random_state=42)\n",
    "elastic_net.fit(np.concatenate((x_train_poly, x_val_poly) ), np.concatenate((y_train, y_val)))\n",
    "\n",
    "# Previsão do algoritmo\n",
    "y_pred = elastic_net.predict(x_test_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 7.39%\n",
      "MSE: 450.92\n",
      "RMSE: 21.23487697162383\n",
      "MAE: 16.863723703549972\n",
      "MAPE: 8.471959630133684\n"
     ]
    }
   ],
   "source": [
    "#Métricas de performance para dados de teste\n",
    "\n",
    "polinomial_regression_elastic_net_test_R2 = r2_squared_out_10 = np.round(100 * mt.r2_score(y_test, y_pred), 2)\n",
    "polinomial_regression_elastic_net_test_MSE = mse_out_10 = np.round(mt.mean_squared_error(y_test, y_pred), 2)\n",
    "polinomial_regression_elastic_net_test_RMSE = rmse_out_10 = np.sqrt(mse_out_10)\n",
    "polinomial_regression_elastic_net_test_MAE = mt.mean_absolute_error(y_test, y_pred)\n",
    "polinomial_regression_elastic_net_test_MAPE = mt.mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "print(f\"R²: {polinomial_regression_elastic_net_test_R2}%\")\n",
    "print(f\"MSE: {polinomial_regression_elastic_net_test_MSE}\")\n",
    "print(f\"RMSE: {polinomial_regression_elastic_net_test_RMSE}\")\n",
    "print(f\"MAE: {polinomial_regression_elastic_net_test_MAE}\")\n",
    "print(f\"MAPE: {polinomial_regression_elastic_net_test_MAPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algoritmo</th>\n",
       "      <th>R²</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>4.6100</td>\n",
       "      <td>451.4600</td>\n",
       "      <td>21.2476</td>\n",
       "      <td>16.8945</td>\n",
       "      <td>787.9977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree Regression</td>\n",
       "      <td>11.3500</td>\n",
       "      <td>423.7500</td>\n",
       "      <td>20.5852</td>\n",
       "      <td>16.3688</td>\n",
       "      <td>7.8695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest Regression</td>\n",
       "      <td>90.6300</td>\n",
       "      <td>44.8100</td>\n",
       "      <td>6.6940</td>\n",
       "      <td>4.7988</td>\n",
       "      <td>2.6280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Polynomial Regression</td>\n",
       "      <td>72.5300</td>\n",
       "      <td>131.3100</td>\n",
       "      <td>11.4591</td>\n",
       "      <td>7.2662</td>\n",
       "      <td>2.2153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Linear Regression Lasso</td>\n",
       "      <td>4.5930</td>\n",
       "      <td>456.0600</td>\n",
       "      <td>21.3556</td>\n",
       "      <td>17.0021</td>\n",
       "      <td>8.6607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Linear Regression Ridge</td>\n",
       "      <td>4.6058</td>\n",
       "      <td>456.0000</td>\n",
       "      <td>21.3542</td>\n",
       "      <td>16.9982</td>\n",
       "      <td>8.6532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Linear Regression Elastic Net</td>\n",
       "      <td>4.5808</td>\n",
       "      <td>456.1200</td>\n",
       "      <td>21.3570</td>\n",
       "      <td>17.0031</td>\n",
       "      <td>8.6615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Polynomial Regression Lasso</td>\n",
       "      <td>15.4800</td>\n",
       "      <td>404.0200</td>\n",
       "      <td>20.1002</td>\n",
       "      <td>15.8145</td>\n",
       "      <td>7.8242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Polynomial Regression Ridge</td>\n",
       "      <td>47.5600</td>\n",
       "      <td>250.6500</td>\n",
       "      <td>15.8319</td>\n",
       "      <td>11.7498</td>\n",
       "      <td>5.0227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Algoritmo      R²      MSE    RMSE     MAE     MAPE\n",
       "0              Linear Regression  4.6100 451.4600 21.2476 16.8945 787.9977\n",
       "1       Decision Tree Regression 11.3500 423.7500 20.5852 16.3688   7.8695\n",
       "2       Random Forest Regression 90.6300  44.8100  6.6940  4.7988   2.6280\n",
       "3          Polynomial Regression 72.5300 131.3100 11.4591  7.2662   2.2153\n",
       "4        Linear Regression Lasso  4.5930 456.0600 21.3556 17.0021   8.6607\n",
       "5        Linear Regression Ridge  4.6058 456.0000 21.3542 16.9982   8.6532\n",
       "6  Linear Regression Elastic Net  4.5808 456.1200 21.3570 17.0031   8.6615\n",
       "7    Polynomial Regression Lasso 15.4800 404.0200 20.1002 15.8145   7.8242\n",
       "8    Polynomial Regression Ridge 47.5600 250.6500 15.8319 11.7498   5.0227"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tabela regressão sobre os dados de treinamento\n",
    "\n",
    "dados = {\n",
    "    \"Algoritmo\": [\n",
    "        \"Linear Regression\",\n",
    "        \"Decision Tree Regression\",\n",
    "        \"Random Forest Regression\",\n",
    "        \"Polynomial Regression\",\n",
    "        \"Linear Regression Lasso\",\n",
    "        \"Linear Regression Ridge\",\n",
    "        \"Linear Regression Elastic Net\",\n",
    "        \"Polynomial Regression Lasso\",\n",
    "        \"Polynomial Regression Ridge\",\n",
    "    ],\n",
    "    \"R²\": [\n",
    "        linear_regression_train_R2,\n",
    "        decision_tree_regression_train_R2,\n",
    "        random_forest_regressor_train_R2,\n",
    "        polinomial_regression_train_R2,\n",
    "        linear_regression_lasso_train_R2,\n",
    "        linear_regression_ridge_train_R2,\n",
    "        linear_regression_elastic_net_train_R2,\n",
    "        polinomial_regression_lasso_train_R2,\n",
    "        polinomial_regression_ridge_train_R2,\n",
    "    ],\n",
    "    \"MSE\": [\n",
    "        linear_regression_train_MSE,\n",
    "        decision_tree_regression_train_MSE,\n",
    "        random_forest_regressor_train_MSE,\n",
    "        polinomial_regression_train_MSE,\n",
    "        linear_regression_lasso_train_MSE,\n",
    "        linear_regression_ridge_train_MSE,\n",
    "        linear_regression_elastic_net_train_MSE,\n",
    "        polinomial_regression_lasso_train_MSE,\n",
    "        polinomial_regression_ridge_train_MSE,\n",
    "    ],\n",
    "    \"RMSE\": [\n",
    "        linear_regression_train_RMSE,\n",
    "        decision_tree_regression_train_RMSE,\n",
    "        random_forest_regressor_train_RMSE,\n",
    "        polinomial_regression_train_RMSE,\n",
    "        linear_regression_lasso_train_RMSE,\n",
    "        linear_regression_ridge_train_RMSE,\n",
    "        linear_regression_elastic_net_train_RMSE,\n",
    "        polinomial_regression_lasso_train_RMSE,\n",
    "        polinomial_regression_ridge_train_RMSE,\n",
    "    ],\n",
    "    \"MAE\": [\n",
    "        linear_regression_train_MAE,\n",
    "        decision_tree_regression_train_MAE,\n",
    "        random_forest_regressor_train_MAE,\n",
    "        polinomial_regression_train_MAE,\n",
    "        linear_regression_lasso_train_MAE,\n",
    "        linear_regression_ridge_train_MAE,\n",
    "        linear_regression_elastic_net_train_MAE,\n",
    "        polinomial_regression_lasso_train_MAE,\n",
    "        polinomial_regression_ridge_train_MAE,\n",
    "    ],\n",
    "    \"MAPE\": [\n",
    "        linear_regression_train_MAPE,\n",
    "        decision_tree_regression_train_MAPE,\n",
    "        random_forest_regressor_train_MAPE,\n",
    "        polinomial_regression_train_MAPE,\n",
    "        linear_regression_lasso_train_MAPE,\n",
    "        linear_regression_ridge_train_MAPE,\n",
    "        linear_regression_elastic_net_train_MAPE,\n",
    "        polinomial_regression_lasso_train_MAPE,\n",
    "        polinomial_regression_ridge_train_MAPE,\n",
    "    ],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(dados)\n",
    "\n",
    "pd.set_option(\"display.float_format\", \"{:.4f}\".format)\n",
    "\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algoritmo</th>\n",
       "      <th>R2</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>4.1900</td>\n",
       "      <td>454.8600</td>\n",
       "      <td>21.3274</td>\n",
       "      <td>16.9413</td>\n",
       "      <td>8.2382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree Regression</td>\n",
       "      <td>6.3600</td>\n",
       "      <td>447.1600</td>\n",
       "      <td>21.1462</td>\n",
       "      <td>16.8435</td>\n",
       "      <td>8.3958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest Regression</td>\n",
       "      <td>34.0000</td>\n",
       "      <td>315.1400</td>\n",
       "      <td>17.7522</td>\n",
       "      <td>12.9357</td>\n",
       "      <td>7.0369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Polynomial Regression</td>\n",
       "      <td>6.6500</td>\n",
       "      <td>445.7700</td>\n",
       "      <td>21.1133</td>\n",
       "      <td>16.7499</td>\n",
       "      <td>8.5479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Linear Regression Lasso</td>\n",
       "      <td>3.9900</td>\n",
       "      <td>458.4500</td>\n",
       "      <td>21.4114</td>\n",
       "      <td>17.0382</td>\n",
       "      <td>8.6862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Linear Regression Ridge</td>\n",
       "      <td>3.9900</td>\n",
       "      <td>458.4400</td>\n",
       "      <td>21.4112</td>\n",
       "      <td>17.0376</td>\n",
       "      <td>8.6813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Linear Regression Elastic Net</td>\n",
       "      <td>3.9900</td>\n",
       "      <td>458.4600</td>\n",
       "      <td>21.4117</td>\n",
       "      <td>17.0368</td>\n",
       "      <td>8.6845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Polynomial Regression Lasso</td>\n",
       "      <td>5.8700</td>\n",
       "      <td>449.4700</td>\n",
       "      <td>21.2007</td>\n",
       "      <td>16.8155</td>\n",
       "      <td>8.6260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Polynomial Regression Ridge</td>\n",
       "      <td>6.7700</td>\n",
       "      <td>445.1800</td>\n",
       "      <td>21.0993</td>\n",
       "      <td>16.7387</td>\n",
       "      <td>8.5690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Algoritmo      R2      MSE    RMSE     MAE   MAPE\n",
       "0              Linear Regression  4.1900 454.8600 21.3274 16.9413 8.2382\n",
       "1       Decision Tree Regression  6.3600 447.1600 21.1462 16.8435 8.3958\n",
       "2       Random Forest Regression 34.0000 315.1400 17.7522 12.9357 7.0369\n",
       "3          Polynomial Regression  6.6500 445.7700 21.1133 16.7499 8.5479\n",
       "4        Linear Regression Lasso  3.9900 458.4500 21.4114 17.0382 8.6862\n",
       "5        Linear Regression Ridge  3.9900 458.4400 21.4112 17.0376 8.6813\n",
       "6  Linear Regression Elastic Net  3.9900 458.4600 21.4117 17.0368 8.6845\n",
       "7    Polynomial Regression Lasso  5.8700 449.4700 21.2007 16.8155 8.6260\n",
       "8    Polynomial Regression Ridge  6.7700 445.1800 21.0993 16.7387 8.5690"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tabela regressão sobre os dados de validação\n",
    "dados = {\n",
    "    \"Algoritmo\": [\n",
    "        \"Linear Regression\", \n",
    "        \"Decision Tree Regression\", \n",
    "        \"Random Forest Regression\", \n",
    "        \"Polynomial Regression\", \n",
    "        \"Linear Regression Lasso\", \n",
    "        \"Linear Regression Ridge\", \n",
    "        \"Linear Regression Elastic Net\", \n",
    "        \"Polynomial Regression Lasso\", \n",
    "        \"Polynomial Regression Ridge\"\n",
    "    ],\n",
    "    \"R2\": [\n",
    "        linear_regression_val_R2, \n",
    "        decision_tree_regression_val_R2, \n",
    "        random_forest_regressor_val_R2, \n",
    "        polinomial_regression_val_R2, \n",
    "        linear_regression_lasso_val_R2, \n",
    "        linear_regression_ridge_val_R2, \n",
    "        linear_regression_elastic_net_val_R2, \n",
    "        polinomial_regression_lasso_val_R2, \n",
    "        polinomial_regression_ridge_val_R2\n",
    "    ],\n",
    "    \"MSE\": [\n",
    "        linear_regression_val_MSE, \n",
    "        decision_tree_regression_val_MSE, \n",
    "        random_forest_regressor_val_MSE, \n",
    "        polinomial_regression_val_MSE, \n",
    "        linear_regression_lasso_val_MSE, \n",
    "        linear_regression_ridge_val_MSE, \n",
    "        linear_regression_elastic_net_val_MSE, \n",
    "        polinomial_regression_lasso_val_MSE, \n",
    "        polinomial_regression_ridge_val_MSE\n",
    "    ],\n",
    "    \"RMSE\": [\n",
    "        linear_regression_val_RMSE, \n",
    "        decision_tree_regression_val_RMSE, \n",
    "        random_forest_regressor_val_RMSE, \n",
    "        polinomial_regression_val_RMSE, \n",
    "        linear_regression_lasso_val_RMSE, \n",
    "        linear_regression_ridge_val_RMSE, \n",
    "        linear_regression_elastic_net_val_RMSE, \n",
    "        polinomial_regression_lasso_val_RMSE, \n",
    "        polinomial_regression_ridge_val_RMSE\n",
    "    ],\n",
    "    \"MAE\": [\n",
    "        linear_regression_val_MAE, \n",
    "        decision_tree_regression_val_MAE, \n",
    "        random_forest_regressor_val_MAE, \n",
    "        polinomial_regression_val_MAE, \n",
    "        linear_regression_lasso_val_MAE, \n",
    "        linear_regression_ridge_val_MAE, \n",
    "        linear_regression_elastic_net_val_MAE, \n",
    "        polinomial_regression_lasso_val_MAE, \n",
    "        polinomial_regression_ridge_val_MAE\n",
    "    ],\n",
    "    \"MAPE\": [\n",
    "        linear_regression_val_MAPE, \n",
    "        decision_tree_regression_val_MAPE, \n",
    "        random_forest_regressor_val_MAPE, \n",
    "        polinomial_regression_val_MAPE, \n",
    "        linear_regression_lasso_val_MAPE, \n",
    "        linear_regression_ridge_val_MAPE, \n",
    "        linear_regression_elastic_net_val_MAPE,\n",
    "        polinomial_regression_lasso_val_MAPE,\n",
    "        polinomial_regression_ridge_val_MAPE]\n",
    " \n",
    "}\n",
    "\n",
    "# Criar o DataFrame (a tabela)\n",
    "df = pd.DataFrame(dados)\n",
    "\n",
    "pd.set_option(\"display.float_format\", \"{:.4f}\".format)\n",
    "\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algoritmo</th>\n",
       "      <th>R2</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>4.2700</td>\n",
       "      <td>460.4700</td>\n",
       "      <td>21.4586</td>\n",
       "      <td>17.1102</td>\n",
       "      <td>8.0103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree Regression</td>\n",
       "      <td>9.0500</td>\n",
       "      <td>442.8500</td>\n",
       "      <td>21.0440</td>\n",
       "      <td>16.8298</td>\n",
       "      <td>7.8832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest Regression</td>\n",
       "      <td>40.6200</td>\n",
       "      <td>289.1100</td>\n",
       "      <td>17.0032</td>\n",
       "      <td>12.2103</td>\n",
       "      <td>6.2827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Polynomial Regression</td>\n",
       "      <td>9.0900</td>\n",
       "      <td>442.6400</td>\n",
       "      <td>21.0390</td>\n",
       "      <td>16.7364</td>\n",
       "      <td>8.2770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Linear Regression Lasso</td>\n",
       "      <td>5.0800</td>\n",
       "      <td>462.1700</td>\n",
       "      <td>21.4981</td>\n",
       "      <td>17.1453</td>\n",
       "      <td>8.5491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Linear Regression Ridge</td>\n",
       "      <td>5.1100</td>\n",
       "      <td>462.0100</td>\n",
       "      <td>21.4944</td>\n",
       "      <td>17.1424</td>\n",
       "      <td>8.5378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Linear Regression Elastic Net</td>\n",
       "      <td>5.0600</td>\n",
       "      <td>462.2500</td>\n",
       "      <td>21.5000</td>\n",
       "      <td>17.1446</td>\n",
       "      <td>8.5551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Polynomial Regression Lasso</td>\n",
       "      <td>7.6600</td>\n",
       "      <td>449.6000</td>\n",
       "      <td>21.2038</td>\n",
       "      <td>16.8444</td>\n",
       "      <td>8.4414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Polynomial Regression Ridge</td>\n",
       "      <td>9.0200</td>\n",
       "      <td>442.9700</td>\n",
       "      <td>21.0469</td>\n",
       "      <td>16.7422</td>\n",
       "      <td>8.3085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Algoritmo      R2      MSE    RMSE     MAE   MAPE\n",
       "0              Linear Regression  4.2700 460.4700 21.4586 17.1102 8.0103\n",
       "1       Decision Tree Regression  9.0500 442.8500 21.0440 16.8298 7.8832\n",
       "2       Random Forest Regression 40.6200 289.1100 17.0032 12.2103 6.2827\n",
       "3          Polynomial Regression  9.0900 442.6400 21.0390 16.7364 8.2770\n",
       "4        Linear Regression Lasso  5.0800 462.1700 21.4981 17.1453 8.5491\n",
       "5        Linear Regression Ridge  5.1100 462.0100 21.4944 17.1424 8.5378\n",
       "6  Linear Regression Elastic Net  5.0600 462.2500 21.5000 17.1446 8.5551\n",
       "7    Polynomial Regression Lasso  7.6600 449.6000 21.2038 16.8444 8.4414\n",
       "8    Polynomial Regression Ridge  9.0200 442.9700 21.0469 16.7422 8.3085"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tabela regressão sobre os dados de teste\n",
    "dados = {\n",
    "    \"Algoritmo\": [\n",
    "        \"Linear Regression\", \n",
    "        \"Decision Tree Regression\", \n",
    "        \"Random Forest Regression\", \n",
    "        \"Polynomial Regression\", \n",
    "        \"Linear Regression Lasso\", \n",
    "        \"Linear Regression Ridge\", \n",
    "        \"Linear Regression Elastic Net\", \n",
    "        \"Polynomial Regression Lasso\", \n",
    "        \"Polynomial Regression Ridge\"\n",
    "    ],\n",
    "    \"R2\": [\n",
    "        linear_regression_test_R2, \n",
    "        decision_tree_regression_test_R2, \n",
    "        random_forest_regressor_test_R2, \n",
    "        polinomial_regression_test_R2, \n",
    "        linear_regression_lasso_test_R2, \n",
    "        linear_regression_ridge_test_R2, \n",
    "        linear_regression_elastic_net_test_R2, \n",
    "        polinomial_regression_lasso_test_R2, \n",
    "        polinomial_regression_ridge_test_R2\n",
    "    ],\n",
    "    \"MSE\": [\n",
    "        linear_regression_test_MSE, \n",
    "        decision_tree_regression_test_MSE, \n",
    "        random_forest_regressor_test_MSE, \n",
    "        polinomial_regression_test_MSE, \n",
    "        linear_regression_lasso_test_MSE, \n",
    "        linear_regression_ridge_test_MSE, \n",
    "        linear_regression_elastic_net_test_MSE, \n",
    "        polinomial_regression_lasso_test_MSE, \n",
    "        polinomial_regression_ridge_test_MSE\n",
    "    ],\n",
    "    \"RMSE\": [\n",
    "        linear_regression_test_RMSE, \n",
    "        decision_tree_regression_test_RMSE, \n",
    "        random_forest_regressor_test_RMSE, \n",
    "        polinomial_regression_test_RMSE, \n",
    "        linear_regression_lasso_test_RMSE, \n",
    "        linear_regression_ridge_test_RMSE, \n",
    "        linear_regression_elastic_net_test_RMSE, \n",
    "        polinomial_regression_lasso_test_RMSE, \n",
    "        polinomial_regression_ridge_test_RMSE\n",
    "    ],\n",
    "    \"MAE\": [\n",
    "        linear_regression_test_MAE, \n",
    "        decision_tree_regression_test_MAE, \n",
    "        random_forest_regressor_test_MAE, \n",
    "        polinomial_regression_test_MAE, \n",
    "        linear_regression_lasso_test_MAE, \n",
    "        linear_regression_ridge_test_MAE, \n",
    "        linear_regression_elastic_net_test_MAE, \n",
    "        polinomial_regression_lasso_test_MAE, \n",
    "        polinomial_regression_ridge_test_MAE\n",
    "    ],\n",
    "    \"MAPE\": [\n",
    "        linear_regression_test_MAPE, \n",
    "        decision_tree_regression_test_MAPE, \n",
    "        random_forest_regressor_test_MAPE, \n",
    "        polinomial_regression_test_MAPE, \n",
    "        linear_regression_lasso_test_MAPE, \n",
    "        linear_regression_ridge_test_MAPE, \n",
    "        linear_regression_elastic_net_test_MAPE, \n",
    "        polinomial_regression_lasso_test_MAPE, \n",
    "        polinomial_regression_ridge_test_MAPE\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Criar o DataFrame (a tabela)\n",
    "df = pd.DataFrame(dados)\n",
    "\n",
    "pd.set_option(\"display.float_format\", \"{:.4f}\".format)\n",
    "\n",
    "display(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
